{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "256a9c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "from torch.nn.functional import normalize\n",
    "import pickle \n",
    "import torch.nn.functional as F \n",
    "import numpy as np \n",
    "from sklearn.metrics import f1_score\n",
    "from torch import nn, optim\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "import numpy as np\n",
    "import pickle\n",
    "import random\n",
    "from scipy import sparse\n",
    "import itertools\n",
    "from scipy.io import savemat, loadmat\n",
    "import re\n",
    "import string\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import torch\n",
    "import pandas as pd\n",
    "import sys\n",
    "sys.path.insert(1, '/home/ec2-user/SageMaker/github/aspect_topic_modeling')\n",
    "import swifter\n",
    "from src.models.utils import remove_stopWords\n",
    "from src.models.utils import get_wordnet_pos, remove_stopWords, get_emb, generate_emb, train, kld_normal, get_common_words, generate_bow\n",
    "from collections import Counter\n",
    "from models.NVDM import topic_covariance_penalty, sinkhorn_torch, NTM, negative_sampling_prior, optimal_transport_prior,  NormalParameter, get_mlp, EmbTopic, NSSTM, OTETM\n",
    "from src.models.utils import get_wordnet_pos, remove_stopWords, get_emb, generate_emb, train, kld_normal, get_common_words\n",
    "from hyperspherical_vae.distributions import VonMisesFisher\n",
    "from hyperspherical_vae.distributions import HypersphericalUniform\n",
    "from src.features.metric import diversity, get_topic_coherence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "62b6c28b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/SageMaker/github/aspect_topic_modeling/notebooks\r\n"
     ]
    }
   ],
   "source": [
    "!pwd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a873c32",
   "metadata": {},
   "source": [
    "# 20News"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "462a8c35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading data...\n"
     ]
    }
   ],
   "source": [
    "# 20News Data\n",
    "print('reading data...')\n",
    "data = fetch_20newsgroups(subset = 'all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a64c60ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'filenames', 'target_names', 'target', 'DESCR'])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "30377086",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "df['class'] = data['target']\n",
    "df['text'] = data['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "370d2335",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18846, 2)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c4995cdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d1e128401a74f8dba41d188637daaf6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dask Apply:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18777734599c48d68ae8352abed207f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dask Apply:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "NameError",
     "evalue": "name 'Counter' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-8abef1ec04eb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'clean_text'\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mswifter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mcommon_words_ct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCounter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'clean_text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mcommon_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_common_words\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommon_words_ct\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mword_track\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mind\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommon_words\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Counter' is not defined"
     ]
    }
   ],
   "source": [
    "df['text'] = df.swifter.apply(lambda x: ' '.join(remove_stopWords(x['text'])), axis=1)\n",
    "df['clean_text']  = df.swifter.apply(lambda x: x['text'].split(), axis = 1)\n",
    "\n",
    "common_words_ct = Counter([j for i in df['clean_text'].values for j in i])\n",
    "common_words = get_common_words(common_words_ct, ct = 200)\n",
    "word_track = {i: ind for ind, i in enumerate(common_words)}\n",
    "index_track = {ind: i for ind, i in enumerate(common_words)}\n",
    "df['index_num'] = df.apply(\n",
    "            lambda x: [word_track[i] for i in x['clean_text'] if i in word_track], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f4d0e12f",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('/home/ec2-user/SageMaker/ORMCorpVoatp/ormcorpvoatp/ormcorpvoatp/data/Spherical-Text-Embedding/datasets/20news/text.txt',\n",
    "           df['text'].values,\n",
    "           fmt='%s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "26bdf8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#change it to any location you save your embeddings\n",
    "vec = '/home/ec2-user/SageMaker/ORMCorpVoatp/ormcorpvoatp/ormcorpvoatp/data/Spherical-Text-Embedding/datasets/20news/jose.txt'\n",
    "embed = generate_emb(vec, common_words).cpu()\n",
    "X, indices = generate_bow(df = df, common_words = common_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "a8627ff2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10,  3, 17, ...,  3,  1,  7])"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1da15905",
   "metadata": {},
   "source": [
    "# TWN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c01abb2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import reuters\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f64afa1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package reuters to /home/ec2-user/nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('reuters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d08ba926",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acq ---- 2661 documents out of 11887\n",
      "alum ---- 62 documents out of 11887\n",
      "barley ---- 58 documents out of 11887\n",
      "bop ---- 120 documents out of 11887\n",
      "carcass ---- 69 documents out of 11887\n",
      "castor-oil ---- 2 documents out of 11887\n",
      "cocoa ---- 81 documents out of 11887\n",
      "coconut ---- 6 documents out of 11887\n",
      "coconut-oil ---- 7 documents out of 11887\n",
      "coffee ---- 141 documents out of 11887\n",
      "copper ---- 73 documents out of 11887\n",
      "copra-cake ---- 3 documents out of 11887\n",
      "corn ---- 270 documents out of 11887\n",
      "cotton ---- 65 documents out of 11887\n",
      "cotton-oil ---- 3 documents out of 11887\n",
      "cpi ---- 108 documents out of 11887\n",
      "cpu ---- 6 documents out of 11887\n",
      "crude ---- 658 documents out of 11887\n",
      "dfl ---- 3 documents out of 11887\n",
      "dlr ---- 223 documents out of 11887\n",
      "dmk ---- 15 documents out of 11887\n",
      "earn ---- 4211 documents out of 11887\n",
      "fuel ---- 23 documents out of 11887\n",
      "gas ---- 65 documents out of 11887\n",
      "gnp ---- 146 documents out of 11887\n",
      "gold ---- 131 documents out of 11887\n",
      "grain ---- 640 documents out of 11887\n",
      "groundnut ---- 9 documents out of 11887\n",
      "groundnut-oil ---- 2 documents out of 11887\n",
      "heat ---- 20 documents out of 11887\n",
      "hog ---- 23 documents out of 11887\n",
      "housing ---- 23 documents out of 11887\n",
      "income ---- 22 documents out of 11887\n",
      "instal-debt ---- 8 documents out of 11887\n",
      "interest ---- 570 documents out of 11887\n",
      "ipi ---- 60 documents out of 11887\n",
      "iron-steel ---- 56 documents out of 11887\n",
      "jet ---- 5 documents out of 11887\n",
      "jobs ---- 73 documents out of 11887\n",
      "l-cattle ---- 8 documents out of 11887\n",
      "lead ---- 30 documents out of 11887\n",
      "lei ---- 19 documents out of 11887\n",
      "lin-oil ---- 2 documents out of 11887\n",
      "livestock ---- 102 documents out of 11887\n",
      "lumber ---- 16 documents out of 11887\n",
      "meal-feed ---- 51 documents out of 11887\n",
      "money-fx ---- 835 documents out of 11887\n",
      "money-supply ---- 230 documents out of 11887\n",
      "naphtha ---- 6 documents out of 11887\n",
      "nat-gas ---- 113 documents out of 11887\n",
      "nickel ---- 10 documents out of 11887\n",
      "nkr ---- 4 documents out of 11887\n",
      "nzdlr ---- 4 documents out of 11887\n",
      "oat ---- 16 documents out of 11887\n",
      "oilseed ---- 185 documents out of 11887\n",
      "orange ---- 32 documents out of 11887\n",
      "palladium ---- 4 documents out of 11887\n",
      "palm-oil ---- 41 documents out of 11887\n",
      "palmkernel ---- 3 documents out of 11887\n",
      "pet-chem ---- 33 documents out of 11887\n",
      "platinum ---- 15 documents out of 11887\n",
      "potato ---- 6 documents out of 11887\n",
      "propane ---- 6 documents out of 11887\n",
      "rand ---- 3 documents out of 11887\n",
      "rape-oil ---- 8 documents out of 11887\n",
      "rapeseed ---- 27 documents out of 11887\n",
      "reserves ---- 83 documents out of 11887\n",
      "retail ---- 29 documents out of 11887\n",
      "rice ---- 64 documents out of 11887\n",
      "rubber ---- 51 documents out of 11887\n",
      "rye ---- 3 documents out of 11887\n",
      "ship ---- 295 documents out of 11887\n",
      "silver ---- 30 documents out of 11887\n",
      "sorghum ---- 37 documents out of 11887\n",
      "soy-meal ---- 28 documents out of 11887\n",
      "soy-oil ---- 26 documents out of 11887\n",
      "soybean ---- 124 documents out of 11887\n",
      "strategic-metal ---- 28 documents out of 11887\n",
      "sugar ---- 170 documents out of 11887\n",
      "sun-meal ---- 2 documents out of 11887\n",
      "sun-oil ---- 7 documents out of 11887\n",
      "sunseed ---- 16 documents out of 11887\n",
      "tea ---- 13 documents out of 11887\n",
      "tin ---- 30 documents out of 11887\n",
      "trade ---- 524 documents out of 11887\n",
      "veg-oil ---- 128 documents out of 11887\n",
      "wheat ---- 304 documents out of 11887\n",
      "wpi ---- 32 documents out of 11887\n",
      "yen ---- 70 documents out of 11887\n",
      "zinc ---- 36 documents out of 11887\n",
      "Articles belong to 1.2333 categories on average\n",
      "There are 132.0778 articles per category on average\n"
     ]
    }
   ],
   "source": [
    "cats = reuters.categories()\n",
    "total = len(reuters.paras())\n",
    "total_multi = 0\n",
    "for c in cats:\n",
    "    lc = len(reuters.paras(categories=[c]))\n",
    "    total_multi += lc\n",
    "    print(\"%s ---- %d documents out of %d\" % (c, lc, total))\n",
    "print(\"Articles belong to %.4f categories on average\" % ((total_multi * 1.0) / total))\n",
    "print(\"There are %.4f articles per category on average\" % ((total * 1.0) / len(cats)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a98b0fbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['DUTCH',\n",
       "  'OFFICIAL',\n",
       "  'RATE',\n",
       "  'CUT',\n",
       "  'SEEN',\n",
       "  'STILL',\n",
       "  'LIKELY',\n",
       "  'A',\n",
       "  'cut',\n",
       "  'of',\n",
       "  'about',\n",
       "  'half',\n",
       "  'a',\n",
       "  'percentage',\n",
       "  'point',\n",
       "  'in',\n",
       "  'Dutch',\n",
       "  'official',\n",
       "  'interest',\n",
       "  'rates',\n",
       "  'is',\n",
       "  'still',\n",
       "  'in',\n",
       "  'prospect',\n",
       "  ',',\n",
       "  'although',\n",
       "  'economists',\n",
       "  'said',\n",
       "  'the',\n",
       "  'timing',\n",
       "  'would',\n",
       "  'depend',\n",
       "  'on',\n",
       "  'Bundesbank',\n",
       "  'moves',\n",
       "  '.'],\n",
       " ['Speculation',\n",
       "  'has',\n",
       "  'been',\n",
       "  'rife',\n",
       "  'that',\n",
       "  'the',\n",
       "  'Dutch',\n",
       "  'Central',\n",
       "  'Bank',\n",
       "  ',',\n",
       "  'encouraged',\n",
       "  'by',\n",
       "  'a',\n",
       "  'strong',\n",
       "  'guilder',\n",
       "  '/',\n",
       "  'mark',\n",
       "  'relationship',\n",
       "  'and',\n",
       "  'wide',\n",
       "  'premiums',\n",
       "  'for',\n",
       "  'Dutch',\n",
       "  'money',\n",
       "  'and',\n",
       "  'capital',\n",
       "  'market',\n",
       "  'rates',\n",
       "  'over',\n",
       "  'German',\n",
       "  ',',\n",
       "  'might',\n",
       "  'lower',\n",
       "  'rates',\n",
       "  'without',\n",
       "  'the',\n",
       "  'Bundesbank',\n",
       "  'moving',\n",
       "  'first',\n",
       "  '.'],\n",
       " ['Last',\n",
       "  'month',\n",
       "  ',',\n",
       "  'the',\n",
       "  'Central',\n",
       "  'Bank',\n",
       "  'lowered',\n",
       "  'its',\n",
       "  'special',\n",
       "  'advances',\n",
       "  'rate',\n",
       "  'to',\n",
       "  '5',\n",
       "  '.',\n",
       "  '1',\n",
       "  'pct',\n",
       "  'from',\n",
       "  '5',\n",
       "  '.',\n",
       "  '25',\n",
       "  'pct',\n",
       "  'after',\n",
       "  'the',\n",
       "  'Bundesbank',\n",
       "  'dropped',\n",
       "  'its',\n",
       "  'repurchase',\n",
       "  'tender',\n",
       "  'rate',\n",
       "  'to',\n",
       "  '3',\n",
       "  '.',\n",
       "  '55',\n",
       "  'pct',\n",
       "  'from',\n",
       "  '3',\n",
       "  '.',\n",
       "  '8',\n",
       "  'pct',\n",
       "  '.'],\n",
       " ['That',\n",
       "  'rate',\n",
       "  'has',\n",
       "  'remained',\n",
       "  'in',\n",
       "  'force',\n",
       "  ',',\n",
       "  'just',\n",
       "  'holding',\n",
       "  'above',\n",
       "  'the',\n",
       "  'five',\n",
       "  'pct',\n",
       "  'official',\n",
       "  'secured',\n",
       "  'loans',\n",
       "  'rate',\n",
       "  'which',\n",
       "  'governs',\n",
       "  'commercial',\n",
       "  'bank',\n",
       "  'borrowings',\n",
       "  '.'],\n",
       " ['Given',\n",
       "  'a',\n",
       "  'strong',\n",
       "  'guilder',\n",
       "  ',',\n",
       "  'a',\n",
       "  'further',\n",
       "  'fall',\n",
       "  'in',\n",
       "  'the',\n",
       "  'West',\n",
       "  'German',\n",
       "  'repo',\n",
       "  'rate',\n",
       "  'would',\n",
       "  'trigger',\n",
       "  'a',\n",
       "  'lower',\n",
       "  'special',\n",
       "  'advances',\n",
       "  'tariff',\n",
       "  ',',\n",
       "  'forcing',\n",
       "  'an',\n",
       "  'official',\n",
       "  'Dutch',\n",
       "  'rate',\n",
       "  'cut',\n",
       "  ',',\n",
       "  'analysts',\n",
       "  'said',\n",
       "  '.'],\n",
       " ['In',\n",
       "  'February',\n",
       "  ',',\n",
       "  'when',\n",
       "  'the',\n",
       "  'Bundesbank',\n",
       "  'cut',\n",
       "  'its',\n",
       "  'discount',\n",
       "  'rate',\n",
       "  'to',\n",
       "  'three',\n",
       "  'pct',\n",
       "  'from',\n",
       "  '3',\n",
       "  '.',\n",
       "  '5',\n",
       "  'pct',\n",
       "  ',',\n",
       "  'the',\n",
       "  'Central',\n",
       "  'Bank',\n",
       "  'only',\n",
       "  'lowered',\n",
       "  'money',\n",
       "  'market',\n",
       "  'rates',\n",
       "  'and',\n",
       "  'removed',\n",
       "  'a',\n",
       "  'surcharge',\n",
       "  'over',\n",
       "  'the',\n",
       "  'secured',\n",
       "  'loans',\n",
       "  'rate',\n",
       "  'on',\n",
       "  'lending',\n",
       "  'under',\n",
       "  'its',\n",
       "  'three',\n",
       "  'month',\n",
       "  'credit',\n",
       "  'quota',\n",
       "  '.'],\n",
       " ['Since',\n",
       "  'then',\n",
       "  ',',\n",
       "  'however',\n",
       "  ',',\n",
       "  'both',\n",
       "  'the',\n",
       "  'Central',\n",
       "  'Bank',\n",
       "  'and',\n",
       "  'Finance',\n",
       "  'Ministry',\n",
       "  'have',\n",
       "  'made',\n",
       "  'it',\n",
       "  'clear',\n",
       "  'they',\n",
       "  'favour',\n",
       "  'lower',\n",
       "  'official',\n",
       "  'rates',\n",
       "  '.'],\n",
       " ['In',\n",
       "  'April',\n",
       "  ',',\n",
       "  'Central',\n",
       "  'Bank',\n",
       "  'President',\n",
       "  'Wim',\n",
       "  'Duisenberg',\n",
       "  'said',\n",
       "  'he',\n",
       "  'would',\n",
       "  'follow',\n",
       "  'any',\n",
       "  'Bundesbank',\n",
       "  'cut',\n",
       "  ',',\n",
       "  'and',\n",
       "  'last',\n",
       "  'week',\n",
       "  'the',\n",
       "  'Finance',\n",
       "  'Ministry',\n",
       "  'expressed',\n",
       "  'satisfaction',\n",
       "  'when',\n",
       "  'it',\n",
       "  'raised',\n",
       "  '2',\n",
       "  '.',\n",
       "  '25',\n",
       "  'billion',\n",
       "  'guilders',\n",
       "  'with',\n",
       "  'a',\n",
       "  'six',\n",
       "  'pct',\n",
       "  'coupon',\n",
       "  'state',\n",
       "  'loan',\n",
       "  'priced',\n",
       "  'at',\n",
       "  '100',\n",
       "  '.',\n",
       "  '10',\n",
       "  'pct',\n",
       "  'for',\n",
       "  'an',\n",
       "  'effective',\n",
       "  'yield',\n",
       "  'of',\n",
       "  '5',\n",
       "  '.',\n",
       "  '98',\n",
       "  'pct',\n",
       "  ',',\n",
       "  'the',\n",
       "  'lowest',\n",
       "  'since',\n",
       "  '1965',\n",
       "  '.'],\n",
       " ['Technically',\n",
       "  ',',\n",
       "  'analysts',\n",
       "  'said',\n",
       "  ',',\n",
       "  'there',\n",
       "  'has',\n",
       "  'to',\n",
       "  'be',\n",
       "  'a',\n",
       "  'difference',\n",
       "  'between',\n",
       "  'the',\n",
       "  'secured',\n",
       "  'loans',\n",
       "  'rate',\n",
       "  'which',\n",
       "  'applies',\n",
       "  'to',\n",
       "  'lending',\n",
       "  'under',\n",
       "  'the',\n",
       "  'credit',\n",
       "  'quota',\n",
       "  ',',\n",
       "  'and',\n",
       "  'the',\n",
       "  'tariff',\n",
       "  'on',\n",
       "  'special',\n",
       "  'advances',\n",
       "  'which',\n",
       "  'add',\n",
       "  'extra',\n",
       "  'liquidity',\n",
       "  'to',\n",
       "  'the',\n",
       "  'money',\n",
       "  'market',\n",
       "  '.'],\n",
       " ['Bank',\n",
       "  'economists',\n",
       "  'and',\n",
       "  'dealers',\n",
       "  'said',\n",
       "  'a',\n",
       "  'West',\n",
       "  'German',\n",
       "  'move',\n",
       "  'to',\n",
       "  'further',\n",
       "  'lower',\n",
       "  'the',\n",
       "  'rate',\n",
       "  'on',\n",
       "  'securities',\n",
       "  'repurchase',\n",
       "  'pacts',\n",
       "  'would',\n",
       "  'result',\n",
       "  'in',\n",
       "  'the',\n",
       "  'Central',\n",
       "  'Bank',\n",
       "  'easing',\n",
       "  'the',\n",
       "  'special',\n",
       "  'advance',\n",
       "  'rate',\n",
       "  ',',\n",
       "  'provided',\n",
       "  'the',\n",
       "  'guilder',\n",
       "  '/',\n",
       "  'mark',\n",
       "  'relationship',\n",
       "  'permitted',\n",
       "  '.'],\n",
       " ['The',\n",
       "  'Central',\n",
       "  'Bank',\n",
       "  'aims',\n",
       "  'to',\n",
       "  'keep',\n",
       "  'the',\n",
       "  'guilder',\n",
       "  'stable',\n",
       "  'around',\n",
       "  'its',\n",
       "  'parity',\n",
       "  'value',\n",
       "  'within',\n",
       "  'the',\n",
       "  'European',\n",
       "  'Monetary',\n",
       "  'System',\n",
       "  'of',\n",
       "  '112',\n",
       "  '.',\n",
       "  '673',\n",
       "  'guilders',\n",
       "  'per',\n",
       "  '100',\n",
       "  'marks',\n",
       "  '.'],\n",
       " ['Today',\n",
       "  ',',\n",
       "  'foreign',\n",
       "  'exchange',\n",
       "  'buying',\n",
       "  'pushed',\n",
       "  'the',\n",
       "  'mark',\n",
       "  'up',\n",
       "  '10',\n",
       "  'guilder',\n",
       "  'cents',\n",
       "  'to',\n",
       "  '112',\n",
       "  '.',\n",
       "  '705',\n",
       "  'guilders',\n",
       "  'per',\n",
       "  '100',\n",
       "  'at',\n",
       "  'the',\n",
       "  'fix',\n",
       "  ',',\n",
       "  'a',\n",
       "  'level',\n",
       "  'that',\n",
       "  'would',\n",
       "  'not',\n",
       "  'permit',\n",
       "  'a',\n",
       "  'change',\n",
       "  'in',\n",
       "  'the',\n",
       "  'interest',\n",
       "  'rate',\n",
       "  'differential',\n",
       "  'between',\n",
       "  'West',\n",
       "  'Germany',\n",
       "  'and',\n",
       "  'the',\n",
       "  'Netherlands',\n",
       "  ',',\n",
       "  'dealers',\n",
       "  'said',\n",
       "  '.'],\n",
       " ['An',\n",
       "  'economist',\n",
       "  'at',\n",
       "  'ABN',\n",
       "  'Bank',\n",
       "  'said',\n",
       "  'he',\n",
       "  'expected',\n",
       "  'West',\n",
       "  'German',\n",
       "  'and',\n",
       "  'Dutch',\n",
       "  'interest',\n",
       "  'rates',\n",
       "  'to',\n",
       "  'ease',\n",
       "  'in',\n",
       "  'the',\n",
       "  'short',\n",
       "  'term',\n",
       "  '.'],\n",
       " ['However',\n",
       "  ',',\n",
       "  'he',\n",
       "  'said',\n",
       "  'new',\n",
       "  'wage',\n",
       "  'agreements',\n",
       "  'in',\n",
       "  'West',\n",
       "  'Germany',\n",
       "  'had',\n",
       "  'raised',\n",
       "  'inflation',\n",
       "  'expectations',\n",
       "  'which',\n",
       "  'would',\n",
       "  'put',\n",
       "  'upward',\n",
       "  'pressure',\n",
       "  'on',\n",
       "  'interest',\n",
       "  'rates',\n",
       "  'in',\n",
       "  'the',\n",
       "  'longer',\n",
       "  'term',\n",
       "  '.'],\n",
       " ['In',\n",
       "  'the',\n",
       "  'Netherlands',\n",
       "  ',',\n",
       "  'the',\n",
       "  'inflation',\n",
       "  'outlook',\n",
       "  'for',\n",
       "  '1987',\n",
       "  'is',\n",
       "  'nil',\n",
       "  ',',\n",
       "  'or',\n",
       "  'even',\n",
       "  'negative',\n",
       "  ',',\n",
       "  'while',\n",
       "  'the',\n",
       "  'latest',\n",
       "  'official',\n",
       "  'economic',\n",
       "  'forecasts',\n",
       "  'point',\n",
       "  'to',\n",
       "  'a',\n",
       "  'falling',\n",
       "  'rate',\n",
       "  'of',\n",
       "  'economic',\n",
       "  'growth',\n",
       "  '.'],\n",
       " ['\"',\n",
       "  'It',\n",
       "  'will',\n",
       "  'depend',\n",
       "  'on',\n",
       "  'the',\n",
       "  'outcome',\n",
       "  'of',\n",
       "  'collective',\n",
       "  'wage',\n",
       "  'agreement',\n",
       "  'negotiations',\n",
       "  'here',\n",
       "  'whether',\n",
       "  'there',\n",
       "  'could',\n",
       "  'be',\n",
       "  'cost',\n",
       "  'push',\n",
       "  'inflation',\n",
       "  ',\"',\n",
       "  'the',\n",
       "  'ABN',\n",
       "  'economist',\n",
       "  'said',\n",
       "  '.'],\n",
       " ['He',\n",
       "  'said',\n",
       "  'Dutch',\n",
       "  'money',\n",
       "  'supply',\n",
       "  'growth',\n",
       "  ',',\n",
       "  'which',\n",
       "  'ran',\n",
       "  'at',\n",
       "  '3',\n",
       "  '.',\n",
       "  '4',\n",
       "  'pct',\n",
       "  'in',\n",
       "  'January',\n",
       "  ',',\n",
       "  'could',\n",
       "  'also',\n",
       "  'contribute',\n",
       "  'to',\n",
       "  'some',\n",
       "  'inflation',\n",
       "  '.'],\n",
       " ['At',\n",
       "  'Amro',\n",
       "  'Bank',\n",
       "  ',',\n",
       "  'a',\n",
       "  'leading',\n",
       "  'analyst',\n",
       "  'said',\n",
       "  'inflation',\n",
       "  'could',\n",
       "  'run',\n",
       "  'to',\n",
       "  'two',\n",
       "  'pct',\n",
       "  'next',\n",
       "  'year',\n",
       "  '.'],\n",
       " ['The',\n",
       "  'bank',\n",
       "  'expects',\n",
       "  'Dutch',\n",
       "  'capital',\n",
       "  'market',\n",
       "  'rates',\n",
       "  ',',\n",
       "  'currently',\n",
       "  'averaging',\n",
       "  'around',\n",
       "  '6',\n",
       "  '.',\n",
       "  '1',\n",
       "  'pct',\n",
       "  ',',\n",
       "  'to',\n",
       "  'stop',\n",
       "  'easing',\n",
       "  'in',\n",
       "  'the',\n",
       "  'second',\n",
       "  'half',\n",
       "  'of',\n",
       "  'this',\n",
       "  'year',\n",
       "  'and',\n",
       "  'stabilize',\n",
       "  'around',\n",
       "  '5',\n",
       "  '.',\n",
       "  '6',\n",
       "  'pct',\n",
       "  '.'],\n",
       " ['Analysts',\n",
       "  'said',\n",
       "  'an',\n",
       "  'official',\n",
       "  'rate',\n",
       "  'cut',\n",
       "  'could',\n",
       "  'trigger',\n",
       "  'a',\n",
       "  'buying',\n",
       "  'spree',\n",
       "  'on',\n",
       "  'the',\n",
       "  'bond',\n",
       "  'market',\n",
       "  'which',\n",
       "  'would',\n",
       "  'bring',\n",
       "  'yields',\n",
       "  'down',\n",
       "  ',',\n",
       "  'probably',\n",
       "  'only',\n",
       "  'temporarily',\n",
       "  ',',\n",
       "  'while',\n",
       "  'money',\n",
       "  'rates',\n",
       "  'could',\n",
       "  'fall',\n",
       "  'below',\n",
       "  'five',\n",
       "  'pct',\n",
       "  '.'],\n",
       " ['Currently',\n",
       "  ',',\n",
       "  'all',\n",
       "  'periods',\n",
       "  'are',\n",
       "  'traded',\n",
       "  'at',\n",
       "  '5',\n",
       "  '.',\n",
       "  '12',\n",
       "  'to',\n",
       "  '5',\n",
       "  '.',\n",
       "  '25',\n",
       "  'pct',\n",
       "  'in',\n",
       "  'the',\n",
       "  'money',\n",
       "  'market',\n",
       "  '.']]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reuters.paras(categories=['dfl'])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de54dc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b4eb5764",
   "metadata": {},
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "443bc77a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13230412471889824"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> from sklearn import metrics\n",
    ">>> labels_true = [1, 1, 1, 0, 0, 0]\n",
    ">>> labels_pred = [0, 2, 2, 2, 2, 2]\n",
    "\n",
    ">>> metrics.mutual_info_score(labels_true, labels_pred)  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d7758695",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4620981203732969"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_pred = [3, 3, 1, 1, 2, 2]\n",
    "metrics.mutual_info_score(labels_true, labels_pred)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "ced20613",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    " \n",
    "def most_frequent(List):\n",
    "    occurence_count = Counter(List)\n",
    "    return occurence_count.most_common(1)[0][1]\n",
    "   \n",
    "List = [2, 1, 2, 2, 1, 3]\n",
    "print(most_frequent(List))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "1f7bc5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "def top_purity(labels_true, labels_pred):\n",
    "    pred = np.unique(labels_pred)\n",
    "    d = defaultdict(list)\n",
    "    for i, j in zip(labels_pred, labels_true):\n",
    "        d[i].append(j)\n",
    "    ct = []\n",
    "    for i in d:\n",
    "        ct += [Counter(d[i]).most_common(1)[0][1]]\n",
    "        #print(Counter(d[i]).most_common(1)[0], i, len(d[i]))\n",
    "    print(ct)\n",
    "    return np.sum(ct)/len(labels_pred)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "6b4a0d82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[952, 629, 18, 23, 9, 10, 1, 1, 1, 1, 1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1646"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_purity(labels_true, labels_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e4d9c3",
   "metadata": {},
   "source": [
    "# VNTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "id": "f07ea4d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VNTM(nn.Module):\n",
    "    \"\"\"NTM that keeps track of output\n",
    "    \"\"\"\n",
    "    def __init__(self, hidden, normal, h_to_z, topics, layer, top_number, penalty):\n",
    "        super(VNTM, self).__init__()\n",
    "        self.hidden = hidden\n",
    "        #self.normal = normal\n",
    "        self.h_to_z = h_to_z\n",
    "        self.topics = topics\n",
    "        self.output = None\n",
    "        self.drop = nn.Dropout(p=0.5)\n",
    "        self.fc_mean = nn.Linear(layer, top_number)\n",
    "        self.fc_var = nn.Linear(layer, 1)\n",
    "        self.num = top_number\n",
    "        self.penalty = penalty\n",
    "        #self.dirichlet = torch.distributions.dirichlet.Dirichlet((torch.ones(self.topics.k)/self.topics.k).cuda())\n",
    "    def forward(self, x, n_sample=1, epoch = 0):\n",
    "        h = self.hidden(x)\n",
    "        h = self.drop(h)\n",
    "        z_mean = self.fc_mean(h)\n",
    "        z_mean = z_mean / z_mean.norm(dim=-1, keepdim=True)\n",
    "        # the `+ 1` prevent collapsing behaviors\n",
    "        z_var = F.softplus(self.fc_var(h)) + 1\n",
    "        \n",
    "        q_z = VonMisesFisher(z_mean, z_var)\n",
    "        p_z = HypersphericalUniform(self.num - 1, device=device)\n",
    "        kld = torch.distributions.kl.kl_divergence(q_z, p_z).mean()\n",
    "        #print(q_z)\n",
    "        #mu, log_sigma = self.normal(h)\n",
    "        #identify how far it is away from normal distribution\n",
    "        \n",
    "        #print(kld.shape)\n",
    "        rec_loss = 0\n",
    "        for i in range(n_sample):\n",
    "            #reparametrician trick\n",
    "            z = q_z.rsample()\n",
    "            #z = nn.Softmax()(z)\n",
    "            #decode\n",
    "            #print(z)\n",
    "            \n",
    "            z = self.h_to_z(10 * z)\n",
    "            self.output = z\n",
    "            #print(z)\n",
    "            \n",
    "            #get log probability for reconstruction loss\n",
    "            log_prob = self.topics(z)\n",
    "            rec_loss = rec_loss - (log_prob * x).sum(dim=-1)\n",
    "        #average reconstruction loss\n",
    "        rec_loss = rec_loss / n_sample\n",
    "        #print(rec_loss.shape)\n",
    "        minus_elbo = rec_loss + kld\n",
    "        penalty, var, mean = topic_covariance_penalty(self.topics.topic_emb) \n",
    "        return {\n",
    "            'loss': minus_elbo + penalty * self.penalty,\n",
    "            'minus_elbo': minus_elbo,\n",
    "            'rec_loss': rec_loss,\n",
    "            'kld': kld\n",
    "        }\n",
    "\n",
    "    def get_topics(self):\n",
    "        return self.topics.get_topics()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "id": "fd5c7c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, X, batch_size, epoch, optimizer, scheduler):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.train()\n",
    "    total_nll = 0.0\n",
    "    total_kld = 0.0\n",
    "    total_words = 0\n",
    "    total_penalty = 0.0\n",
    "    #size = epoch_size * batch_size\n",
    "    indices = torch.randperm(X.shape[0])\n",
    "    indices = torch.split(indices, batch_size)\n",
    "    #print(indices)\n",
    "    length = len(indices)\n",
    "    for idx, ind in enumerate(indices):\n",
    "        data_batch = torch.from_numpy(X[ind].toarray()).float().to(device)\n",
    "        \n",
    "        d = model(x = data_batch)\n",
    "            \n",
    "        \n",
    "        \n",
    "        total_nll += d['rec_loss'].sum().item() / batch_size\n",
    "        total_kld += d['kld'].sum().item() / batch_size  \n",
    "        #total_penalty += d['prior']  \n",
    "#         if i < 3:\n",
    "#             loss = d['minus_elbo']\n",
    "#         else:\n",
    "        loss = d['loss']\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.sum().backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "    print(total_nll/length, total_kld/length)\n",
    "     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "id": "d2cc8912",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/ipykernel/__main__.py:41: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "852.0981940192145 0.0023696595382864108\n",
      "827.4855519887564 0.016863887210854807\n",
      "798.30655690786 0.02468017753012277\n",
      "776.2857109276024 0.028754686609514662\n",
      "765.3556720630543 0.029878672338216693\n",
      "759.0351537756018 0.03044270973249867\n",
      "754.4659192884291 0.03450010261322196\n",
      "752.3947927114126 0.036022817741173344\n",
      "750.7459675556904 0.03327914277041281\n",
      "749.6035197489971 0.033533523941563594\n",
      "747.9836178341427 0.03254409529570792\n",
      "747.6197880925359 0.031194197920125885\n",
      "747.0079040527344 0.030624974267305555\n",
      "746.4548442943676 0.029769035509309254\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-414-9d707958760d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-411-ae882023c876>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, X, batch_size, epoch, optimizer, scheduler)\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mdata_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mind\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-410-112ffaf082b7>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, n_sample, epoch)\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_sample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0;31m#reparametrician trick\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m             \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mq_z\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrsample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m             \u001b[0;31m#z = nn.Softmax()(z)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0;31m#decode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/SageMaker/github/aspect_topic_modeling/hyperspherical_vae/distributions/von_mises_fisher.py\u001b[0m in \u001b[0;36mrsample\u001b[0;34m(self, shape)\u001b[0m\n\u001b[1;32m     55\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__sample_w3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__m\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m             \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__sample_w_rej\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m         )\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/SageMaker/github/aspect_topic_modeling/hyperspherical_vae/distributions/von_mises_fisher.py\u001b[0m in \u001b[0;36m__sample_w_rej\u001b[0;34m(self, shape)\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__m\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__m\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__b\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__e\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__w\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__while_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__w\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/SageMaker/github/aspect_topic_modeling/hyperspherical_vae/distributions/von_mises_fisher.py\u001b[0m in \u001b[0;36m__while_loop\u001b[0;34m(self, b, a, d, shape, k, eps)\u001b[0m\n\u001b[1;32m    151\u001b[0m             \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0me_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m             \u001b[0maccept\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__m\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mt\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m             \u001b[0maccept_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfirst_nonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccept\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minvalid_val\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m             \u001b[0maccept_idx_clamped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccept_idx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclamp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "            numb_embeddings = 20\n",
    "            hidden = get_mlp([X.shape[1], 128], nn.ReLU)\n",
    "            normal = NormalParameter(128, 20)\n",
    "            h_to_z = nn.Softmax()\n",
    "            embedding = nn.Embedding(X.shape[1], 50)\n",
    "            # p1d = (0, 0, 0, 10000 - company1.embeddings.shape[0]) # pad last dim by 1 on each side\n",
    "            # out = F.pad(company1.embeddings, p1d, \"constant\", 0)  # effectively zero padding\n",
    "\n",
    "            embedding.weight = torch.nn.Parameter(torch.Tensor(embed.float()))\n",
    "            embedding.weight.requires_grad=False\n",
    "            topics = EmbTopic(embedding = embedding,\n",
    "                              k = numb_embeddings, normalize = False)\n",
    "\n",
    "\n",
    "\n",
    "            device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "            model = VNTM(hidden = hidden,\n",
    "                        normal = normal,\n",
    "                        h_to_z = h_to_z,\n",
    "                        topics = topics,\n",
    "                        layer = 128, \n",
    "                        top_number = numb_embeddings,\n",
    "                        penalty = 0.5\n",
    "                        ).to(device).float()\n",
    "            # larger hidden size make topics more diverse\n",
    "            #num_docs_train = 996318\n",
    "            batch_size = 256\n",
    "            optimizer = optim.Adam(model.parameters(), \n",
    "                                   lr=0.002, \n",
    "                                   weight_decay=1.2e-6)\n",
    "\n",
    "            epochs = 20\n",
    "            scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=0.05, steps_per_epoch=int(X.shape[0]/batch_size) + 1, epochs=epochs)\n",
    "\n",
    "            \n",
    "            for epoch in range(epochs):\n",
    "                train(model, X,  batch_size, epoch, optimizer, scheduler)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "id": "f9eeb065",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/ipykernel/__main__.py:9: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[872, 792, 640, 339, 890, 204, 776, 788, 779, 734, 43, 71, 458, 130, 15]\n",
      "[758, 643, 684, 186, 216, 851, 271, 689, 97, 630, 716, 202, 730, 319, 237, 213, 63, 108, 617, 160]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.3996073437334182,\n",
       " 0.4839303169812979,\n",
       " 0.44518730765149106,\n",
       " 0.48417940107607277)"
      ]
     },
     "execution_count": 415,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#prior(softmax_top, indexes)\n",
    "emb = model.topics.get_topics().cpu().detach().numpy()\n",
    "topics =  [[index_track[ind] for ind in np.argsort(emb[i])[::-1][:25] ] for i in range(10)]\n",
    "data_batch = torch.from_numpy(X.toarray()).float()\n",
    "model.cpu()\n",
    "z = model.hidden(data_batch)\n",
    "z_mean = model.fc_mean(z)\n",
    "z_mean = z_mean / z_mean.norm(dim=-1, keepdim=True)\n",
    "z = model.h_to_z(z_mean)\n",
    "\n",
    "\n",
    "labels_pred = torch.argmax(z, 1).numpy()\n",
    "labels_true = df['class'].values\n",
    " \n",
    "\n",
    "diversity_score = np.mean(diversity(topics))\n",
    "#coherence_score = get_topic_coherence(X.toarray(), topics, word_track)\n",
    "from sklearn.cluster import KMeans\n",
    "kmeans = KMeans(n_clusters=20, random_state=0).fit(z.detach().numpy())\n",
    "top_purity(labels_true, labels_pred), metrics.normalized_mutual_info_score(labels_true, labels_pred), top_purity(labels_true, kmeans.labels_), metrics.normalized_mutual_info_score(labels_true, kmeans.labels_)  \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "id": "25be7591",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.4, 0.84, 0.32, 0.72, 0.64, 0.6, 0.4, 0.44, 0.92, 0.96], 0.624)"
      ]
     },
     "execution_count": 417,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diversity(topics), np.mean(diversity(topics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "id": "953377ed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5040000000000001, -0.40466082922081026)"
      ]
     },
     "execution_count": 473,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation, NMF\n",
    "\n",
    "lda = LatentDirichletAllocation(n_components=20, random_state=0)\n",
    "lda.fit(X)\n",
    "topic_index = np.argsort(lda.components_, axis=1)[:, -25:]\n",
    "topics = [[index_track[j] for j in i] for i in topic_index]\n",
    "np.mean(diversity(topics)), np.mean(get_topic_coherence(X.toarray(), topics, word_track))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "id": "c9914905",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LatentDirichletAllocation(n_components=20, random_state=0)"
      ]
     },
     "execution_count": 477,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "333f0dc1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b19abadd",
   "metadata": {},
   "source": [
    "# NTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "bf453ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, X, batch_size, epoch, optimizer):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.train()\n",
    "    total_nll = 0.0\n",
    "    total_kld = 0.0\n",
    "    total_words = 0\n",
    "    total_penalty = 0.0\n",
    "    #size = epoch_size * batch_size\n",
    "    indices = torch.randperm(X.shape[0])\n",
    "    indices = torch.split(indices, batch_size)\n",
    "    #print(indices)\n",
    "    length = len(indices)\n",
    "    for idx, ind in enumerate(indices):\n",
    "        data_batch = torch.from_numpy(X[ind].toarray()).float().to(device)\n",
    "        \n",
    "        d = model(x = data_batch)\n",
    "            \n",
    "        \n",
    "        \n",
    "        total_nll += d['rec_loss'].sum().item() / batch_size\n",
    "        total_kld += d['kld'].sum().item() / batch_size  \n",
    "        #total_penalty += d['penalty'].sum().item() / batch_size  \n",
    "#         if i < 3:\n",
    "#             loss = d['minus_elbo']\n",
    "#         else:\n",
    "        loss = d['loss']\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.sum().backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(total_nll/length, total_kld/length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "fee38a86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0005, 0.0005, 0.0004,  ..., 0.0003, 0.0004, 0.0005],\n",
       "        [0.0005, 0.0004, 0.0004,  ..., 0.0004, 0.0005, 0.0004],\n",
       "        [0.0003, 0.0003, 0.0005,  ..., 0.0005, 0.0005, 0.0005],\n",
       "        ...,\n",
       "        [0.0004, 0.0005, 0.0003,  ..., 0.0004, 0.0005, 0.0004],\n",
       "        [0.0004, 0.0005, 0.0005,  ..., 0.0003, 0.0004, 0.0004],\n",
       "        [0.0005, 0.0004, 0.0004,  ..., 0.0005, 0.0004, 0.0004]])"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics = Topics(numb_embeddings, X.shape[1])\n",
    "topics.get_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "0a12e5e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "836.3474549989443 0.1607032038548307\n",
      "819.3788678968275 0.03806465583526202\n",
      "806.9361918681377 0.03929201230985691\n",
      "797.9546310837204 0.048760768302993196\n",
      "791.4055390229096 0.04600683428548478\n",
      "786.7550077696104 0.038150564075221084\n",
      "783.4681206780512 0.02321837155299412\n",
      "781.0415558686127 0.025440513194110746\n",
      "779.4308673755543 0.04452345746481237\n",
      "778.4024130331503 0.0753821546048228\n",
      "777.6905938225824 0.06864226998987834\n",
      "777.3639212943413 0.023134106206959364\n",
      "776.9615222827808 0.1023010356647491\n",
      "776.8203562143686 0.06381778039881406\n",
      "776.6001384838207 0.0499157341703697\n",
      "776.7200680294552 0.10331941790236915\n",
      "776.361110377956 0.13221442471793224\n",
      "776.5740822456978 0.11337339315198462\n",
      "776.1798528722815 0.162217427351877\n",
      "776.2847937506598 0.10506580079704322\n"
     ]
    }
   ],
   "source": [
    "from models.NVDM import NTM\n",
    "import gc\n",
    "#labels = [[120], [1527], [1646], [2047], [727], [1624], [36], [32], [26], [92], [907], [652]]\n",
    "numb_embeddings = 20\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "hidden = get_mlp([X.shape[1], 64], nn.ReLU)\n",
    "normal = NormalParameter(64, numb_embeddings)\n",
    "h_to_z = nn.Softmax()\n",
    "embedding = nn.Embedding(X.shape[1], 50)\n",
    "# p1d = (0, 0, 0, 10000 - company1.embeddings.shape[0]) # pad last dim by 1 on each side\n",
    "# out = F.pad(company1.embeddings, p1d, \"constant\", 0)  # effectively zero padding\n",
    "\n",
    "# embedding.weight = torch.nn.Parameter(torch.Tensor(embed.float()))\n",
    "# embedding.weight.requires_grad=False\n",
    "topics = Topics(numb_embeddings, X.shape[1])\n",
    "\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "model = NTM(hidden = hidden,\n",
    "            normal = normal,\n",
    "            h_to_z = h_to_z,\n",
    "            topics = topics\n",
    "            ).to(device).float()\n",
    "# larger hidden size make topics more diverse\n",
    "#num_docs_train = 996318\n",
    "batch_size = 256\n",
    "optimizer = optim.Adam(model.parameters(), \n",
    "                       lr=0.002, \n",
    "                       weight_decay=1.2e-6)\n",
    "\n",
    "\n",
    "\n",
    "epochs = 20\n",
    "scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=0.05, steps_per_epoch=int(X.shape[0]/batch_size) + 1, epochs=epochs)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train(model, X,  batch_size, epoch, optimizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "1106acd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/ipykernel/__main__.py:4: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[964, 624, 19, 21, 9, 6, 1, 1, 1, 1]\n",
      "[981, 67, 121, 14, 51, 58, 81, 120, 14, 8, 18, 4, 21, 12, 29, 7, 23, 4, 13, 5]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.08739255014326648,\n",
       " 0.09698613336289995,\n",
       " 0.08760479677385122,\n",
       " 0.12068967614918263)"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h = model.hidden(data_batch)\n",
    "h = model.drop(h)\n",
    "mu, log_sigma = model.normal(h)\n",
    "z = model.h_to_z(mu)\n",
    "labels_pred = torch.argmax(z, 1).numpy()\n",
    "labels_true = df['class'].values\n",
    "diversity_score = np.mean(diversity(topics))\n",
    "from sklearn.cluster import KMeans\n",
    "kmeans = KMeans(n_clusters=20, random_state=0).fit(z.detach().numpy())\n",
    "top_purity(labels_true, labels_pred), metrics.mutual_info_score(labels_true, labels_pred), top_purity(labels_true, kmeans.labels_), metrics.mutual_info_score(labels_true, kmeans.labels_)  \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "5563b91f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.64, 0.64, 0.72, 1.0, 0.84, 1.0, 0.88, 0.68, 0.76, 0.92]"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "e67af67a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([list(['from', 'mamatha', 'devineni', 'ratnam', 'mr47', 'andrew', 'cmu', 'edu', 'subject', 'pen', 'fan', 'reaction', 'organization', 'post', 'office', 'carnegie', 'mellon', 'pittsburgh', 'pa', 'line', '12', 'nntp', 'post', 'host', 'po4', 'andrew', 'cmu', 'edu', 'i', 'be', 'sure', 'some', 'bashers', 'of', 'pen', 'fan', 'be', 'pretty', 'confuse', 'about', 'the', 'lack', 'of', 'any', 'kind', 'of', 'post', 'about', 'the', 'recent', 'pen', 'massacre', 'of', 'the', 'devil', 'actually', 'i', 'be', 'bit', 'puzzled', 'too', 'and', 'a', 'bit', 'relieved', 'however', 'i', 'be', 'go', 'to', 'put', 'an', 'end', 'to', 'non', 'pittsburghers', 'relief', 'with', 'a', 'bit', 'of', 'praise', 'for', 'the', 'pen', 'man', 'they', 'be', 'kill', 'those', 'devil', 'bad', 'than', 'i', 'think', 'jagr', 'just', 'show', 'you', 'why', 'he', 'be', 'much', 'good', 'than', 'his', 'regular', 'season', 'stats', 'he', 'be', 'also', 'a', 'lot', 'fo', 'fun', 'to', 'watch', 'in', 'the', 'playoff', 'bowman', 'should', 'let', 'jagr', 'have', 'a', 'lot', 'of', 'fun', 'in', 'the', 'next', 'couple', 'of', 'game', 'since', 'the', 'pen', 'be', 'go', 'to', 'beat', 'the', 'pulp', 'out', 'of', 'jersey', 'anyway', 'i', 'be', 'very', 'disappointed', 'not', 'to', 'see', 'the', 'islander', 'lose', 'the', 'final', 'regular', 'season', 'game', 'pen', 'rule']),\n",
       "       list(['from', 'mblawson', 'midway', 'ecn', 'uoknor', 'edu', 'matthew', 'b', 'lawson', 'subject', 'which', 'high', 'performance', 'vlb', 'video', 'card', 'summary', 'seek', 'recommendation', 'for', 'vlb', 'video', 'card', 'nntp', 'post', 'host', 'midway', 'ecn', 'uoknor', 'edu', 'organization', 'engineering', 'computer', 'network', 'university', 'of', 'oklahoma', 'norman', 'ok', 'usa', 'keywords', 'orchid', 'stealth', 'vlb', 'line', '21', 'my', 'brother', 'be', 'in', 'the', 'market', 'for', 'a', 'high', 'performance', 'video', 'card', 'that', 'support', 'vesa', 'local', 'bus', 'with', '1', '2mb', 'ram', 'do', 'anyone', 'have', 'suggestion', 'idea', 'on', 'diamond', 'stealth', 'pro', 'local', 'bus', 'orchid', 'farenheit', '1280', 'ati', 'graphic', 'ultra', 'pro', 'any', 'other', 'high', 'performance', 'vlb', 'card', 'please', 'post', 'or', 'email', 'thank', 'you', 'matt', 'matthew', 'b', 'lawson', 'mblawson', 'essex', 'ecn', 'uoknor', 'edu', 'now', 'i', 'nebuchadnezzar', 'praise', 'and', 'exalt', 'and', 'glorify', 'the', 'king', 'of', 'heaven', 'because', 'everything', 'he', 'do', 'be', 'right', 'and', 'all', 'his', 'way', 'be', 'just', 'nebuchadnezzar', 'king', 'of', 'babylon', '562', 'b', 'c'])],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a9868cf9",
   "metadata": {},
   "source": [
    "# GSM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "id": "7f41d61a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GSM(NTM):\n",
    "    def __init__(self, hidden, normal, h_to_z, topics, penalty):\n",
    "        # h_to_z will output probabilities over topics\n",
    "        super(GSM, self).__init__(hidden, normal, h_to_z, topics)\n",
    "        self.penalty = penalty\n",
    "\n",
    "    def forward(self, x, n_sample=1):\n",
    "        stat = super(GSM, self).forward(x, n_sample)\n",
    "        loss = stat['loss']\n",
    "        penalty, var, mean = topic_covariance_penalty(self.topics.topic_emb)\n",
    "\n",
    "        stat.update({\n",
    "            'loss': loss + penalty * self.penalty,\n",
    "            'penalty_mean': mean,\n",
    "            'penalty_var': var,\n",
    "            'penalty': penalty * self.penalty,\n",
    "        })\n",
    "\n",
    "        return stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "id": "427ede18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2394, 50])"
      ]
     },
     "execution_count": 435,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "id": "42314f3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/SageMaker/github/aspect_topic_modeling/models/NVDM.py:73: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  z = self.h_to_z(z)\n"
     ]
    },
    {
     "ename": "ModuleAttributeError",
     "evalue": "'Topics' object has no attribute 'topic_emb'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleAttributeError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-459-0e64c4aff286>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-411-ae882023c876>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, X, batch_size, epoch, optimizer, scheduler)\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mdata_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mind\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-427-2285d16cdd29>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, n_sample)\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mstat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGSM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_sample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mpenalty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtopic_covariance_penalty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtopics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtopic_emb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         stat.update({\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    777\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m         raise ModuleAttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0;32m--> 779\u001b[0;31m             type(self).__name__, name))\n\u001b[0m\u001b[1;32m    780\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Module'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleAttributeError\u001b[0m: 'Topics' object has no attribute 'topic_emb'"
     ]
    }
   ],
   "source": [
    "from models.NVDM import NTM\n",
    "import gc\n",
    "#labels = [[120], [1527], [1646], [2047], [727], [1624], [36], [32], [26], [92], [907], [652]]\n",
    "numb_embeddings = 20\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "hidden = get_mlp([X.shape[1], 64], nn.ReLU)\n",
    "normal = NormalParameter(64, numb_embeddings)\n",
    "h_to_z = nn.Softmax()\n",
    "embedding = nn.Embedding(X.shape[1], 50)\n",
    "# p1d = (0, 0, 0, 10000 - company1.embeddings.shape[0]) # pad last dim by 1 on each side\n",
    "# out = F.pad(company1.embeddings, p1d, \"constant\", 0)  # effectively zero padding\n",
    "\n",
    "embedding.weight = torch.nn.Parameter(torch.ones(embed.shape))\n",
    "# embedding.weight.requires_grad=False\n",
    "#embedding.weight = torch.nn.Parameter()\n",
    "embedding.weight.requires_grad=True\n",
    "topics = EmbTopic(embedding = embedding,\n",
    "                  \n",
    "                  k = numb_embeddings, normalize = False)\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "model = GSM(hidden = hidden,\n",
    "            normal = normal,\n",
    "            h_to_z = h_to_z,\n",
    "            topics = topics,\n",
    "            penalty = 1\n",
    "        \n",
    "            ).to(device).float()\n",
    "# larger hidden size make topics more diverse\n",
    "#num_docs_train = 996318\n",
    "batch_size = 256\n",
    "optimizer = optim.Adam(model.parameters(), \n",
    "                       lr=0.002, \n",
    "                       weight_decay=1.2e-6)\n",
    "\n",
    "\n",
    "\n",
    "epochs = 20\n",
    "scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=0.001, steps_per_epoch=int(X.shape[0]/batch_size) + 1, epochs=epochs)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train(model, X,  batch_size, epoch, optimizer, scheduler)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "id": "17c9397b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/ipykernel/__main__.py:9: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[887, 863, 374, 417, 152, 954, 494, 126, 4, 12]\n",
      "[252, 398, 151, 150, 573, 307, 234, 370, 249, 225, 195, 63, 315, 65, 254, 86, 100, 63, 246, 10]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.2272630796986098,\n",
       " 0.29222802899938016,\n",
       " 0.22848349782447203,\n",
       " 0.2981286821704531)"
      ]
     },
     "execution_count": 444,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#prior(softmax_top, indexes)\n",
    "emb = model.topics.get_topics().cpu().detach().numpy()\n",
    "topics =  [[index_track[ind] for ind in np.argsort(emb[i])[::-1][:25] ] for i in range(20)]\n",
    "data_batch = torch.from_numpy(X.toarray()).float()\n",
    "model.cpu()\n",
    "h = model.hidden(data_batch)\n",
    "h = model.drop(h)\n",
    "mu, log_sigma = model.normal(h)\n",
    "z = model.h_to_z(mu)\n",
    "labels_pred = torch.argmax(z, 1).numpy()\n",
    "labels_true = df['class'].values\n",
    "diversity_score = np.mean(diversity(topics))\n",
    "from sklearn.cluster import KMeans\n",
    "kmeans = KMeans(n_clusters=20, random_state=0).fit(z.detach().numpy())\n",
    "top_purity(labels_true, labels_pred), metrics.normalized_mutual_info_score(labels_true, labels_pred), top_purity(labels_true, kmeans.labels_), metrics.normalized_mutual_info_score(labels_true, kmeans.labels_)  \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "id": "eb5302fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.23600000000000004"
      ]
     },
     "execution_count": 445,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(diversity(topics))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "id": "c5d848a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/SageMaker/github/aspect_topic_modeling/models/NVDM.py:73: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  z = self.h_to_z(z)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "850.2488122888514 0.3557278318582354\n",
      "848.9807928961676 0.36526529450674317\n",
      "846.1792619035051 0.7726792844163405\n",
      "842.8049926757812 1.4372556644517023\n",
      "839.5003381677576 1.8342022106454179\n",
      "835.8960084657411 2.2670185904245117\n",
      "832.7783161885029 2.7266449058378064\n",
      "829.2468360694679 3.1057512148006543\n",
      "826.2967389080975 3.359474810394081\n",
      "823.8363948512722 3.713141703927839\n",
      "821.5484652132601 3.7246873443191117\n",
      "819.6407594423036 3.865933759792431\n",
      "817.949026159338 4.055987548183751\n",
      "816.4779432142103 4.0030235052108765\n",
      "815.4905651195629 4.030273927224649\n",
      "814.7514087573902 4.010774493217468\n",
      "814.2587771029085 4.141421417932253\n",
      "814.0171698492926 4.032950752490276\n",
      "813.7811163824957 4.0853450233871875\n",
      "813.7942315178949 4.082697945672113\n"
     ]
    }
   ],
   "source": [
    "from models.NVDM import NTM\n",
    "import gc\n",
    "#labels = [[120], [1527], [1646], [2047], [727], [1624], [36], [32], [26], [92], [907], [652]]\n",
    "numb_embeddings = 20\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "hidden = get_mlp([X.shape[1],  64], nn.ReLU)\n",
    "normal = NormalParameter(64, numb_embeddings)\n",
    "h_to_z = nn.Softmax()\n",
    "embedding = nn.Embedding(X.shape[1], 50)\n",
    "# p1d = (0, 0, 0, 10000 - company1.embeddings.shape[0]) # pad last dim by 1 on each side\n",
    "# out = F.pad(company1.embeddings, p1d, \"constant\", 0)  # effectively zero padding\n",
    "\n",
    "# embedding.weight = torch.nn.Parameter(torch.Tensor(embed.float()))\n",
    "# embedding.weight.requires_grad=False\n",
    "embedding.weight = torch.nn.Parameter(torch.Tensor(embed.float()))\n",
    "embedding.weight.requires_grad=False\n",
    "topics = EmbTopic(embedding = embedding,\n",
    "                  k = numb_embeddings, normalize = False)\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "model = GSM(hidden = hidden,\n",
    "            normal = normal,\n",
    "            h_to_z = h_to_z,\n",
    "            topics = topics,\n",
    "            penalty = 0\n",
    "        \n",
    "            ).to(device).float()\n",
    "# larger hidden size make topics more diverse\n",
    "#num_docs_train = 996318\n",
    "batch_size = 256\n",
    "optimizer = optim.Adam(model.parameters(), \n",
    "                       lr=0.002, \n",
    "                       weight_decay=1.2e-6)\n",
    "\n",
    "\n",
    "\n",
    "epochs = 20\n",
    "scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=0.001, steps_per_epoch=int(X.shape[0]/batch_size) + 1, epochs=epochs)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train(model, X,  batch_size, epoch, optimizer, scheduler)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "id": "82070e76",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/ipykernel/__main__.py:9: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[920, 116, 498, 710, 31, 47, 18, 100, 59, 26, 36, 36, 11, 7, 24, 4, 5, 2]\n",
      "[158, 40, 166, 297, 235, 203, 287, 165, 307, 121, 10, 117, 194, 58, 51, 21, 102, 26, 23, 12]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.1406133927623899,\n",
       " 0.13513739602163383,\n",
       " 0.13758887827655736,\n",
       " 0.10114286736005487)"
      ]
     },
     "execution_count": 429,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#prior(softmax_top, indexes)\n",
    "emb = model.topics.get_topics().cpu().detach().numpy()\n",
    "topics =  [[index_track[ind] for ind in np.argsort(emb[i])[::-1][:25] ] for i in range(20)]\n",
    "data_batch = torch.from_numpy(X.toarray()).float()\n",
    "model.cpu()\n",
    "h = model.hidden(data_batch)\n",
    "h = model.drop(h)\n",
    "mu, log_sigma = model.normal(h)\n",
    "z = model.h_to_z(mu)\n",
    "labels_pred = torch.argmax(z, 1).numpy()\n",
    "labels_true = df['class'].values\n",
    "diversity_score = np.mean(diversity(topics))\n",
    "from sklearn.cluster import KMeans\n",
    "kmeans = KMeans(n_clusters=20, random_state=0).fit(z.detach().numpy())\n",
    "top_purity(labels_true, labels_pred), metrics.normalized_mutual_info_score(labels_true, labels_pred), top_purity(labels_true, kmeans.labels_), metrics.normalized_mutual_info_score(labels_true, kmeans.labels_)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "id": "3e0cf744",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.726"
      ]
     },
     "execution_count": 431,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(diversity(topics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca087f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "id": "a3bc26b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(1, '/home/ec2-user/SageMaker/github/aspect_topic_modeling/pt-avitm')\n",
    "from ptavitm.sklearn_api import ProdLDATransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "id": "fbc93f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ProdLDATransformer(\n",
    "        cuda=device,\n",
    "        batch_size=256,\n",
    "        epochs=80,\n",
    "        hidden1_dimension=64,\n",
    "        hidden2_dimension=64,\n",
    "        topics=20,\n",
    "        lr=0.001,\n",
    "        samples=50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "id": "6d10b321",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "id": "023269f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "id": "7c7cf80b",
   "metadata": {},
   "outputs": [],
   "source": [
    "        decoder_weight = model.autoencoder.decoder.linear.weight.detach().cpu()\n",
    "        id2word = {index: str(index) for index in range(X.shape[1])}\n",
    "        topics = [\n",
    "            [item.item() for item in topic]\n",
    "            for topic in decoder_weight.topk(min(model.score_num, X.shape[1]), dim=0)[\n",
    "                1\n",
    "            ].t()\n",
    "        ]\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "id": "9e64dd39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.8571428571428571,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.8571428571428571,\n",
       " 1.0,\n",
       " 0.7142857142857143,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.8571428571428571,\n",
       " 1.0,\n",
       " 0.5714285714285714]"
      ]
     },
     "execution_count": 549,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diversity(topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "id": "9461f7a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[103, 398, 243, 70, 225, 448, 265, 437, 53, 331, 336, 245, 384, 105, 182, 264, 100, 240, 344, 151]\n",
      "[98, 510, 181, 339, 225, 577, 357, 313, 315, 596, 137, 452, 479, 266, 161, 241, 251, 191, 104, 173]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.2612756022498143,\n",
       " 0.24761351519096145,\n",
       " 0.3165658495171389,\n",
       " 0.3046968220454173)"
      ]
     },
     "execution_count": 556,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_pred = result.argmax(1)\n",
    "labels_true = df['class'].values\n",
    "diversity_score = np.mean(diversity(topics))\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import normalize\n",
    "kmeans = KMeans(n_clusters=20, random_state=0).fit(normalize(result, axis=1))\n",
    "top_purity(labels_true, labels_pred), metrics.normalized_mutual_info_score(labels_true, labels_pred), top_purity(labels_true, kmeans.labels_), metrics.normalized_mutual_info_score(labels_true, kmeans.labels_)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "id": "529638a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.matutils import Sparse2Corpus\n",
    "corpus = Sparse2Corpus(X, documents_columns=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "id": "b1b627a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1877, 1617, 2048, 1968, 1881, 1878, 1754],\n",
       " [835, 2095, 697, 1628, 2010, 711, 1833],\n",
       " [1370, 405, 1948, 1464, 2225, 1413, 2162],\n",
       " [2040, 2031, 1740, 215, 2033, 2032, 254],\n",
       " [1630, 910, 1076, 1935, 1938, 2168, 245],\n",
       " [208, 144, 1598, 1593, 1597, 1243, 1127],\n",
       " [2323, 1158, 2246, 830, 2002, 2014, 1210],\n",
       " [763, 764, 1336, 1567, 758, 462, 2159],\n",
       " [1112, 2272, 1346, 1100, 1239, 567, 1099],\n",
       " [2386, 2392, 2388, 2391, 2382, 2381, 2389],\n",
       " [1638, 1670, 1634, 1269, 2286, 166, 1671],\n",
       " [1461, 1460, 1427, 667, 1462, 1439, 1099],\n",
       " [557, 1614, 2157, 2377, 2345, 334, 1826],\n",
       " [436, 435, 438, 2175, 1034, 2258, 1986],\n",
       " [681, 1193, 2034, 599, 2239, 807, 1859],\n",
       " [1042, 1215, 1146, 1086, 1894, 1043, 1275],\n",
       " [772, 778, 1315, 774, 187, 797, 2223],\n",
       " [1742, 2088, 1744, 2039, 1562, 1745, 446],\n",
       " [1544, 1352, 417, 111, 1405, 335, 1068],\n",
       " [1562, 1542, 435, 91, 425, 438, 1541]]"
      ]
     },
     "execution_count": 560,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "id": "0f486ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "corpus = Sparse2Corpus(X, documents_columns=False)\n",
    "#decoder_weight = self.autoencoder.decoder.linear.weight.detach().cpu()\n",
    "id2word = {index: str(index) for index in range(X.shape[1])}\n",
    "topics = [\n",
    "            [item.item() for item in topic]\n",
    "            for topic in decoder_weight.topk(min(model.score_num, X.shape[1]), dim=0)[\n",
    "                1\n",
    "            ].t()\n",
    "        ]\n",
    " \n",
    "cm = CoherenceModel(\n",
    "    topics=topics,\n",
    "    corpus=corpus,\n",
    "    dictionary=Dictionary.from_corpus(corpus, id2word),\n",
    "    coherence=\"u_mass\",\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "id": "1dc7567d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.04799074373478669"
      ]
     },
     "execution_count": 585,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm = CoherenceModel(\n",
    "    topics=topics,\n",
    "    texts = df.apply(lambda x:[str(i) for i in x['index_num']], axis = 1).values,\n",
    "    corpus=corpus,\n",
    "    dictionary=Dictionary.from_corpus(corpus, id2word),\n",
    "    coherence='c_npmi',\n",
    ")\n",
    "\n",
    "cm.get_coherence()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "id": "9a3e5b9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.010575433373172134,\n",
       " -0.08864524531280475,\n",
       " -0.29738757225699636,\n",
       " -0.12675700414382224,\n",
       " -0.00046802004933244707,\n",
       " -0.2907925052459905,\n",
       " -0.24912661770649866,\n",
       " 0.09824602830557984,\n",
       " -0.07246353833620021,\n",
       " 0.5782802533523147,\n",
       " -0.08915202093578214,\n",
       " 0.19697654636731932,\n",
       " -0.209023759286811,\n",
       " -0.09121954098799176,\n",
       " -0.02777727205228651,\n",
       " 0.039474022414436885,\n",
       " -0.0730726645682248,\n",
       " -0.036998336957972625,\n",
       " -0.09971504504233546,\n",
       " -0.13076801562550727]"
      ]
     },
     "execution_count": 586,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm.get_coherence_per_topic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "id": "e7a46893",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'numpy.ndarray' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-580-adbe7533365f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'index_num'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'numpy.ndarray' object is not callable"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "id": "4bae163d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "id": "97414ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HiddenToLogNormal(nn.Module):\n",
    "    def __init__(self, hidden_size, num_topics):\n",
    "        super().__init__()\n",
    "        self.fcmu = nn.Linear(hidden_size, num_topics)\n",
    "        self.fclv = nn.Linear(hidden_size, num_topics)\n",
    "        self.bnmu = nn.BatchNorm1d(num_topics)\n",
    "        self.bnlv = nn.BatchNorm1d(num_topics)\n",
    "\n",
    "    def forward(self, hidden):\n",
    "        mu = self.bnmu(self.fcmu(hidden))\n",
    "        lv = self.bnlv(self.fclv(hidden))\n",
    "        dist = LogNormal(mu, (0.5 * lv).exp())\n",
    "        return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "id": "8a3c5309",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unindent does not match any outer indentation level (<tokenize>, line 7)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<tokenize>\"\u001b[0;36m, line \u001b[0;32m7\u001b[0m\n\u001b[0;31m    return prior\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "id": "fabf8543",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.distributions import kl_divergence\n",
    "class NTM(nn.Module):\n",
    "    \"\"\"NTM that keeps track of output\n",
    "    \"\"\"\n",
    "    def __init__(self, hidden, normal, h_to_z, topics):\n",
    "        super(NTM, self).__init__()\n",
    "        self.hidden = hidden\n",
    "        self.normal = normal\n",
    "        self.h_to_z = h_to_z\n",
    "        self.topics = topics\n",
    "        self.output = None\n",
    "        self.drop = nn.Dropout(p=0.5)\n",
    "    def forward(self, x, n_sample=1):\n",
    "        h = self.hidden(x)\n",
    "        h = self.drop(h)\n",
    "        posterior = self.normal(h)\n",
    "        prior = standard_prior_like(posterior)\n",
    "        #identify how far it is away from normal distribution\n",
    "        kld = kl_divergence(posterior, prior).mean()\n",
    "        #print(kld.shape)\n",
    "        rec_loss = 0\n",
    "        for i in range(n_sample):\n",
    "            #reparametrician trick\n",
    "            z = posterior.rsample().to(device)\n",
    "            #decode\n",
    "            \n",
    "            z = z / z.sum(1, keepdim=True)\n",
    "            self.output = z\n",
    "            #print(z)\n",
    "            #z = self.drop(z)\n",
    "            #get log probability for reconstruction loss\n",
    "            log_prob = self.topics(z)\n",
    "            rec_loss = rec_loss - (log_prob * x).sum(dim=-1)\n",
    "        #average reconstruction loss\n",
    "        rec_loss = rec_loss / n_sample\n",
    "        #print(rec_loss.shape)\n",
    "        minus_elbo = rec_loss + kld\n",
    "\n",
    "        return {\n",
    "            'loss': minus_elbo,\n",
    "            'minus_elbo': minus_elbo,\n",
    "            'rec_loss': rec_loss,\n",
    "            'kld': kld\n",
    "        }\n",
    "\n",
    "    def get_topics(self):\n",
    "        return self.topics.get_topics()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "id": "88845967",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan nan\n",
      "nan nan\n",
      "nan nan\n",
      "nan nan\n",
      "nan nan\n",
      "nan nan\n",
      "nan nan\n",
      "nan nan\n",
      "nan nan\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-489-5e1872291827>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-411-ae882023c876>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, X, batch_size, epoch, optimizer, scheduler)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    130\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    131\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import gc\n",
    "from torch.distributions import LogNormal, Dirichlet\n",
    "#labels = [[120], [1527], [1646], [2047], [727], [1624], [36], [32], [26], [92], [907], [652]]\n",
    "numb_embeddings = 20\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "hidden = get_mlp([X.shape[1],  64], nn.ReLU)\n",
    "normal = HiddenToLogNormal(64, numb_embeddings)\n",
    "h_to_z = nn.Softmax()\n",
    "embedding = nn.Embedding(X.shape[1], 50)\n",
    "# p1d = (0, 0, 0, 10000 - company1.embeddings.shape[0]) # pad last dim by 1 on each side\n",
    "# out = F.pad(company1.embeddings, p1d, \"constant\", 0)  # effectively zero padding\n",
    "\n",
    "# embedding.weight = torch.nn.Parameter(torch.Tensor(embed.float()))\n",
    "# embedding.weight.requires_grad=False\n",
    "embedding.weight = torch.nn.Parameter(torch.Tensor(embed.float()))\n",
    "embedding.weight.requires_grad=False\n",
    "topics = EmbTopic(embedding = embedding,\n",
    "                  k = numb_embeddings, normalize = False)\n",
    "\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "model = NTM(hidden = hidden,\n",
    "            normal = normal,\n",
    "            h_to_z = h_to_z,\n",
    "            topics = topics\n",
    "            \n",
    "        \n",
    "            ).to(device).float()\n",
    "# larger hidden size make topics more diverse\n",
    "#num_docs_train = 996318\n",
    "batch_size = 256\n",
    "optimizer = optim.Adam(model.parameters(), \n",
    "                       lr=0.002, \n",
    "                       weight_decay=1.2e-6)\n",
    "\n",
    "\n",
    "\n",
    "epochs = 20\n",
    "scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=0.002, steps_per_epoch=int(X.shape[0]/batch_size) + 1, epochs=epochs)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train(model, X,  batch_size, epoch, optimizer, scheduler)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "id": "9fd87dbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[102, 102, 111, 617, 85, 52, 81, 56, 26, 27, 79, 28, 65, 76, 41, 84, 41, 53, 16, 24]\n",
      "[176, 68, 63, 524, 352, 180, 109, 16, 28, 12, 3, 6, 4, 3, 4, 2, 6, 3, 5, 6]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.09370688740316248,\n",
       " 0.031428944734180744,\n",
       " 0.08330680250451024,\n",
       " 0.03507299395058063)"
      ]
     },
     "execution_count": 471,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#prior(softmax_top, indexes)\n",
    "emb = model.topics.get_topics().cpu().detach().numpy()\n",
    "topics =  [[index_track[ind] for ind in np.argsort(emb[i])[::-1][:25] ] for i in range(20)]\n",
    "data_batch = torch.from_numpy(X.toarray()).float()\n",
    "model.cpu()\n",
    "h = model.hidden(data_batch)\n",
    "h = model.drop(h)\n",
    "mu = model.normal(h)\n",
    "z = mu.mean\n",
    "labels_pred = torch.argmax(z, 1).numpy()\n",
    "labels_true = df['class'].values\n",
    "diversity_score = np.mean(diversity(topics))\n",
    "from sklearn.cluster import KMeans\n",
    "kmeans = KMeans(n_clusters=20, random_state=0).fit(z.detach().numpy())\n",
    "top_purity(labels_true, labels_pred), metrics.normalized_mutual_info_score(labels_true, labels_pred), top_purity(labels_true, kmeans.labels_), metrics.normalized_mutual_info_score(labels_true, kmeans.labels_)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "id": "745d1af5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({10: 794,\n",
       "         18: 924,\n",
       "         7: 1669,\n",
       "         17: 5989,\n",
       "         14: 1185,\n",
       "         9: 725,\n",
       "         15: 1019,\n",
       "         11: 470,\n",
       "         6: 211,\n",
       "         13: 292,\n",
       "         4: 831,\n",
       "         5: 371,\n",
       "         0: 643,\n",
       "         2: 914,\n",
       "         19: 441,\n",
       "         8: 1096,\n",
       "         16: 523,\n",
       "         12: 351,\n",
       "         1: 195,\n",
       "         3: 203})"
      ]
     },
     "execution_count": 472,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import collections\n",
    "collections.Counter(labels_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "007def62",
   "metadata": {},
   "source": [
    "# AG News"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bbc7d273",
   "metadata": {},
   "outputs": [],
   "source": [
    "D = pd.read_csv('https://raw.githubusercontent.com/yumeng5/WeSTClass/master/agnews/dataset.csv', names = ['class', 'documents', 'text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1e0ac198",
   "metadata": {},
   "outputs": [],
   "source": [
    "D['clean_text'] = D['documents'] + D['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d1ebc70f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13d2cdfb02ab4dfa8301c2cf205fe08d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dask Apply:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "D['clean_text'] = D.swifter.apply(lambda x: ' '.join(remove_stopWords(x['documents'] + x['text'])).split(), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c3274229",
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate word 2 vec models\n",
    "w2vmodel = Word2Vec(D['clean_text'].values,vector_size=200, window=10, negative = 5, min_count= 10)\n",
    "\n",
    "#generate input for the model\n",
    "vocab = list(set([j for i in init_docs for j in i if j in w2vmodel.wv]))\n",
    "vocab = [''] + vocab\n",
    "word_track = {i: ind for ind, i in enumerate(vocab)}\n",
    "index_track = {ind: i for ind, i in enumerate(vocab)}\n",
    "#pad the input\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3211719f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd5f0457",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1a1643cb",
   "metadata": {},
   "source": [
    "# RCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "981c00f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_rcv1\n",
    "rcv1 = fetch_rcv1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "340dc736",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cannot use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3055df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#backup dataset NYT and Arxiv\n",
    "\n",
    "#https://github.com/yumeng5/JoSH/tree/master/datasets\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_latest_p36",
   "language": "python",
   "name": "conda_pytorch_latest_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
