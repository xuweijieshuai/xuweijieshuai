{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8220a405",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '/home/ec2-user/SageMaker/github/aspect_topic_modeling')\n",
    "import torch\n",
    "from torch.nn.functional import normalize\n",
    "import pickle \n",
    "import torch.nn.functional as F \n",
    "import numpy as np \n",
    "from sklearn.metrics import f1_score\n",
    "from torch import nn, optim\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "import numpy as np\n",
    "import pickle\n",
    "import random\n",
    "from scipy import sparse\n",
    "import itertools\n",
    "from scipy.io import savemat, loadmat\n",
    "import re\n",
    "import string\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import torch\n",
    "import pandas as pd\n",
    "import swifter\n",
    "from src.models.utils import remove_stopWords\n",
    "from src.models.utils import get_wordnet_pos, remove_stopWords, get_emb, generate_emb, train, kld_normal, get_common_words, generate_bow\n",
    "from collections import Counter\n",
    "from models.NVDM import VNTM, topic_covariance_penalty, sinkhorn_torch, NTM, negative_sampling_prior, optimal_transport_prior,  NormalParameter, get_mlp, EmbTopic, NSSTM, OTETM\n",
    "from src.models.utils import get_wordnet_pos, remove_stopWords, get_emb, generate_emb, train, kld_normal, get_common_words\n",
    "from hyperspherical_vae.distributions import VonMisesFisher\n",
    "from hyperspherical_vae.distributions import HypersphericalUniform\n",
    "from src.features.metric import diversity, get_topic_coherence,top_purity\n",
    "from sklearn.cluster import KMeans\n",
    "from collections import Counter\n",
    "from sklearn import metrics\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "from gensim.matutils import Sparse2Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ed05ac25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(topics, X, z, labels):\n",
    "    result = []\n",
    "    result += sorted(diversity(topics))\n",
    "\n",
    "\n",
    "    labels_pred = torch.argmax(z, 1).numpy()\n",
    "    labels_true = labels\n",
    "    #coherence_score = get_topic_coherence(X.toarray(), topics, word_track)\n",
    "    kmeans = KMeans(n_clusters=numb_embeddings, random_state=0).fit(z.detach().numpy())\n",
    "    result += [top_purity(labels_true, labels_pred), metrics.normalized_mutual_info_score(labels_true, labels_pred), top_purity(labels_true, kmeans.labels_), metrics.normalized_mutual_info_score(labels_true, kmeans.labels_)]  \n",
    "    corpus = Sparse2Corpus(X, documents_columns=False)\n",
    "    #decoder_weight = self.autoencoder.decoder.linear.weight.detach().cpu()\n",
    "    id2word = {index: str(index) for index in range(X.shape[1])}\n",
    "    texts = df.apply(lambda x:[str(i) for i in x['index_num']], axis = 1).values\n",
    "    cm = CoherenceModel(\n",
    "                topics=topics,\n",
    "                corpus=corpus,\n",
    "                dictionary=Dictionary.from_corpus(corpus, id2word),\n",
    "                coherence=\"u_mass\",\n",
    "            )\n",
    "    result += [cm.get_coherence()]\n",
    "    cm = CoherenceModel(\n",
    "        topics=topics,\n",
    "        texts = texts,\n",
    "        corpus=corpus,\n",
    "        dictionary=Dictionary.from_corpus(corpus, id2word),\n",
    "        coherence='c_npmi',\n",
    "    )\n",
    "\n",
    "    result += sorted(cm.get_coherence_per_topic())\n",
    "\n",
    "    cm = CoherenceModel(\n",
    "        topics=topics,\n",
    "        texts = texts,\n",
    "        corpus=corpus,\n",
    "        dictionary=Dictionary.from_corpus(corpus, id2word),\n",
    "        coherence='c_v',\n",
    "    )\n",
    "\n",
    "    result += sorted(cm.get_coherence_per_topic())\n",
    "    return result\n",
    "\n",
    "def train(model, X, batch_size, epoch, optimizer, scheduler):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.train()\n",
    "    total_nll = 0.0\n",
    "    total_kld = 0.0\n",
    "    total_words = 0\n",
    "    total_penalty = 0.0\n",
    "    #size = epoch_size * batch_size\n",
    "    indices = torch.randperm(X.shape[0])\n",
    "    indices = torch.split(indices, batch_size)\n",
    "    #print(indices)\n",
    "    length = len(indices)\n",
    "    for idx, ind in enumerate(indices):\n",
    "        data_batch = torch.from_numpy(X[ind].toarray()).float().to(device)\n",
    "        \n",
    "        d = model(x = data_batch)\n",
    "            \n",
    "        \n",
    "        \n",
    "        total_nll += d['rec_loss'].sum().item() / batch_size\n",
    "        total_kld += d['kld'].sum().item() / batch_size  \n",
    "        #total_penalty += d['prior']  \n",
    "#         if i < 3:\n",
    "#             loss = d['minus_elbo']\n",
    "#         else:\n",
    "        loss = d['loss']\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.sum().backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "    print(total_nll/length, total_kld/length)\n",
    "     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "79da219c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a7e0b9aadfb4e76b9b659a446566b99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dask Apply:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73985b80e1d54a078cf041bfaa5a993d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dask Apply:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = fetch_20newsgroups(subset = 'all')\n",
    "df = pd.DataFrame()\n",
    "df['class'] = data['target']\n",
    "df['text'] = data['data']\n",
    "df['text'] = df.swifter.apply(lambda x: ' '.join(remove_stopWords(x['text'])), axis=1)\n",
    "df['clean_text']  = df.swifter.apply(lambda x: x['text'].split(), axis = 1)\n",
    "\n",
    "common_words_ct = Counter([j for i in df['clean_text'].values for j in i])\n",
    "common_words = get_common_words(common_words_ct, ct = 200)\n",
    "word_track = {i: ind for ind, i in enumerate(common_words)}\n",
    "index_track = {ind: i for ind, i in enumerate(common_words)}\n",
    "df['index_num'] = df.apply(\n",
    "            lambda x: [word_track[i] for i in x['clean_text'] if i in word_track], axis=1)\n",
    "#change it to any location you save your embeddings\n",
    "vec = '/home/ec2-user/SageMaker/ORMCorpVoatp/ormcorpvoatp/ormcorpvoatp/data/Spherical-Text-Embedding/datasets/20news/jose.txt'\n",
    "embed = generate_emb(vec, common_words).cpu()\n",
    "X, indices = generate_bow(df = df, common_words = common_words)\n",
    "labels = df['class'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "11a1e307",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c13f915e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/SageMaker/github/aspect_topic_modeling/models/NVDM.py:518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  z = self.h_to_z(10 * z)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "852.3764339137722 0.0003528987258874081\n",
      "833.9358751451647 0.0065030172810185\n",
      "802.7080605996622 0.020629807450884097\n",
      "776.9980361526077 0.02769756314621584\n",
      "766.5454596442145 0.02930298065011566\n",
      "762.1701288996516 0.029433899433226197\n",
      "759.6222435203758 0.028382767017024593\n",
      "757.1568570523649 0.02808703759030716\n",
      "755.48470986856 0.027972861016924318\n",
      "753.9910995895798 0.027753485945632327\n",
      "753.1505753800676 0.026251285286569916\n",
      "752.4136715450802 0.025921327993273735\n",
      "752.4556769293707 0.026337043130518618\n",
      "751.680248363598 0.02590395215697385\n",
      "751.3044062434016 0.02674811937519022\n",
      "751.2801703375738 0.025424336788018007\n",
      "751.1537071434227 0.025275769920365232\n",
      "750.8851887470967 0.025157848171688414\n",
      "750.8321689915012 0.025106761478693097\n",
      "750.8933418892525 0.024943803411883278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/ipykernel/__main__.py:55: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-68d0842f05cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     55\u001b[0m             \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mh_to_z\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz_mean\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtopics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m             \u001b[0mdf\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m             \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'vntm_result.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-43-da515a2469eb>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(topics, X, z)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mlabels_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mlabels_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'class'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0;31m#coherence_score = get_topic_coherence(X.toarray(), topics, word_track)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mkmeans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKMeans\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_clusters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnumb_embeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not str"
     ]
    }
   ],
   "source": [
    "pdf = []\n",
    "for penalty in [0.1, 0.5, 1, 2]:\n",
    "            result = [penalty] \n",
    "            \n",
    "            device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "            numb_embeddings = 20\n",
    "            layer = 64\n",
    "            hidden = get_mlp([X.shape[1], layer], nn.ReLU)\n",
    "            normal = NormalParameter(layer, numb_embeddings)\n",
    "            h_to_z = nn.Softmax()\n",
    "            embedding = nn.Embedding(X.shape[1], 50)\n",
    "            # p1d = (0, 0, 0, 10000 - company1.embeddings.shape[0]) # pad last dim by 1 on each side\n",
    "            # out = F.pad(company1.embeddings, p1d, \"constant\", 0)  # effectively zero padding\n",
    "\n",
    "            embedding.weight = torch.nn.Parameter(torch.Tensor(embed.float()))\n",
    "            embedding.weight.requires_grad=False\n",
    "            topics = EmbTopic(embedding = embedding,\n",
    "                              k = numb_embeddings, normalize = False)\n",
    "\n",
    "\n",
    "\n",
    "            device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "            model = VNTM(hidden = hidden,\n",
    "                        normal = normal,\n",
    "                        h_to_z = h_to_z,\n",
    "                        topics = topics,\n",
    "                        layer = layer, \n",
    "                        top_number = numb_embeddings,\n",
    "                        penalty = penalty\n",
    "                        ).to(device).float()\n",
    "            # larger hidden size make topics more diverse\n",
    "            #num_docs_train = 996318\n",
    "            batch_size = 256\n",
    "            optimizer = optim.Adam(model.parameters(), \n",
    "                                   lr=0.002, \n",
    "                                   weight_decay=1.2e-6)\n",
    "\n",
    "            epochs = 20\n",
    "            scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=0.05, steps_per_epoch=int(X.shape[0]/batch_size) + 1, epochs=epochs)\n",
    "\n",
    "            \n",
    "            for epoch in range(epochs):\n",
    "                train(model, X,  batch_size, epoch, optimizer, scheduler)\n",
    "            #Add Diversity\n",
    "            emb = model.topics.get_topics().cpu().detach().numpy()\n",
    "            topics =  [[str(ind) for ind in np.argsort(emb[i])[::-1][:25] ] for i in range(10)]\n",
    "                #Add purity . \n",
    "            data_batch = torch.from_numpy(X.toarray()).float()\n",
    "            model.cpu()\n",
    "            z = model.hidden(data_batch)\n",
    "            z_mean = model.fc_mean(z)\n",
    "            z_mean = z_mean / z_mean.norm(dim=-1, keepdim=True)\n",
    "            z = model.h_to_z(z_mean)\n",
    "\n",
    "            result += evaluate(topics, X, z, labels)\n",
    "            pdf += [result]\n",
    "            pd.DataFrame(pdf).to_csv('vntm_result.csv')\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "295ea345",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GSM(NTM):\n",
    "    def __init__(self, hidden, normal, h_to_z, topics, penalty):\n",
    "        # h_to_z will output probabilities over topics\n",
    "        super(GSM, self).__init__(hidden, normal, h_to_z, topics)\n",
    "        self.penalty = penalty\n",
    "\n",
    "    def forward(self, x, n_sample=1):\n",
    "        stat = super(GSM, self).forward(x, n_sample)\n",
    "        loss = stat['loss']\n",
    "        penalty, var, mean = topic_covariance_penalty(self.topics.topic_emb)\n",
    "\n",
    "        stat.update({\n",
    "            'loss': loss + penalty * self.penalty,\n",
    "            'penalty_mean': mean,\n",
    "            'penalty_var': var,\n",
    "            'penalty': penalty * self.penalty,\n",
    "        })\n",
    "\n",
    "        return stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "c4b2fbcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "840.2764043034734 0.14752137429408124\n",
      "815.4568110285578 2.7103528992549792\n",
      "783.0952944368929 4.3609197590802165\n",
      "778.784373515361 2.8426911959777006\n",
      "774.6264524717589 2.0234160681028626\n",
      "767.9100135597023 10077.176793913584\n",
      "761.0873215134079 69.3053106391752\n",
      "758.6336665797878 17459687.533643696\n",
      "755.7382354736328 5.221328803010889\n",
      "754.188020448427 7.864280893995955\n",
      "752.6771248482369 5.630689608084189\n",
      "752.2076655207453 5.81131914821831\n",
      "751.0493918753959 1054.950396782643\n",
      "750.3951333535684 292.8652725284164\n",
      "749.6096240894215 5.54470435348717\n",
      "749.1894704457876 5.585414751155956\n",
      "749.0334604624155 5.618317694277377\n",
      "749.0159070813978 5.692249317426939\n",
      "748.7631118362015 5.63982825021486\n",
      "748.6938946698162 5.757757908589131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/ipykernel/__main__.py:57: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[862, 666, 666, 418, 796, 908, 528, 37, 1]\n",
      "[637, 280, 443, 235, 245, 644, 624, 506, 312, 349]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/SageMaker/github/aspect_topic_modeling/models/NVDM.py:76: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  z = self.h_to_z(z)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "841.3765431996939 0.2074762776091292\n",
      "824.7175342456715 1.6799932181633808\n",
      "788.926717397329 4.4504952172975285\n",
      "778.4003398998364 2.7038868504601554\n",
      "771.5081828349346 22.919909606108796\n",
      "767.6175396893475 81561227.25958209\n",
      "765.020475645323 381745.9069249888\n",
      "762.3192369615709 22.672403786633467\n",
      "760.3181300807644 1901.11142216502\n",
      "758.405460254566 91.92166087434099\n",
      "757.46695028769 89.50418971035931\n",
      "755.9209384402714 1051.522579908371\n",
      "755.8784357019373 6.126181818343498\n",
      "754.3259034027924 6.314897157050468\n",
      "753.2341923069309 6.495797630902883\n",
      "752.9509260847761 6.121557989635983\n",
      "752.813206028294 6.317051104597144\n",
      "752.3209310995566 6.2774295678009855\n",
      "752.0234399743982 9.539597479072777\n",
      "752.6269539497994 429.3934269499134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/ipykernel/__main__.py:57: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[842, 799, 957, 264, 497, 355, 202, 77, 1]\n",
      "[236, 128, 235, 420, 156, 204, 263, 224, 506, 269, 287, 151, 194, 253, 208, 103, 48, 39, 11, 18]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/SageMaker/github/aspect_topic_modeling/models/NVDM.py:76: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  z = self.h_to_z(z)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "842.1229982118349 0.29041738848428467\n",
      "828.2131252804318 1.469753977817458\n",
      "791.1007075954128 4.826619865121068\n",
      "778.4166028821791 2.2966643225502326\n",
      "772.4511759989971 56.343130382331644\n",
      "766.5601905616554 3.090942531018644\n",
      "762.3672790527344 12.06990261657818\n",
      "760.5549910261824 122.45083993995512\n",
      "757.7920952874262 73.35032663796399\n",
      "756.0032690924567 9.046773143716761\n",
      "755.075959901552 4422.890766237233\n",
      "754.3145310685442 39526.52317291659\n",
      "753.1285577722498 12.265821118612546\n",
      "752.3087467502903 6.469494764869277\n",
      "751.9834025614971 6.108860354165773\n",
      "751.1051111994562 6.484751063424188\n",
      "750.6703293259079 6.450681032361211\n",
      "750.5690233385241 6.543433969085281\n",
      "749.3702285354202 6.530648663237288\n",
      "750.9291431323902 199604022.4133276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/ipykernel/__main__.py:57: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[889, 650, 960, 573, 138, 575, 621, 544, 8, 15, 1, 1]\n",
      "[188, 127, 135, 246, 323, 448, 289, 159, 146, 255, 274, 270, 60, 172, 92, 200, 116, 79, 160, 144, 142, 106, 24, 73, 54, 81, 208, 71, 41, 13]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-71-338f4c6ef33d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_sigma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mh_to_z\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtopics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m     \u001b[0mpdf\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ntm_result.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-45-e7ee8cc59ca8>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(topics, X, z, labels)\u001b[0m\n\u001b[1;32m     16\u001b[0m                 \u001b[0mtopics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtopics\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                 \u001b[0mcorpus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m                 \u001b[0mdictionary\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDictionary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_corpus\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mid2word\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m                 \u001b[0mcoherence\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"u_mass\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m             )\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/gensim/corpora/dictionary.py\u001b[0m in \u001b[0;36mfrom_corpus\u001b[0;34m(corpus, id2word)\u001b[0m\n\u001b[1;32m    759\u001b[0m                 \u001b[0mmax_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwordid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    760\u001b[0m                 \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_pos\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mword_freq\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 761\u001b[0;31m                 \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdfs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mwordid\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwordid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    762\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mid2word\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from models.NVDM import Topics\n",
    "import gc\n",
    "pdf = []\n",
    "#labels = [[120], [1527], [1646], [2047], [727], [1624], [36], [32], [26], [92], [907], [652]]\n",
    "for numb_embeddings in [10, 20, 30, 40, 50]:\n",
    "    result = [numb_embeddings] \n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    hidden = get_mlp([X.shape[1], 64], nn.ReLU)\n",
    "    normal = NormalParameter(64, numb_embeddings)\n",
    "    h_to_z = nn.Softmax()\n",
    "    embedding = nn.Embedding(X.shape[1], 50)\n",
    "    # p1d = (0, 0, 0, 10000 - company1.embeddings.shape[0]) # pad last dim by 1 on each side\n",
    "    # out = F.pad(company1.embeddings, p1d, \"constant\", 0)  # effectively zero padding\n",
    "\n",
    "    embedding.weight = torch.nn.Parameter(torch.ones(embed.shape))\n",
    "    # embedding.weight.requires_grad=False\n",
    "    #embedding.weight = torch.nn.Parameter()\n",
    "    embedding.weight.requires_grad=True\n",
    "    topics = EmbTopic(embedding = embedding,\n",
    "\n",
    "                      k = numb_embeddings, normalize = False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "    model = GSM(hidden = hidden,\n",
    "                normal = normal,\n",
    "                h_to_z = h_to_z,\n",
    "                topics = topics,\n",
    "                penalty = 0.5\n",
    "                ).to(device).float()\n",
    "    # larger hidden size make topics more diverse\n",
    "    #num_docs_train = 996318\n",
    "    batch_size = 256\n",
    "    optimizer = optim.Adam(model.parameters(), \n",
    "                           lr=0.002, \n",
    "                           weight_decay=1.2e-6)\n",
    "\n",
    "\n",
    "\n",
    "    epochs = 20\n",
    "    scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=0.002, steps_per_epoch=int(X.shape[0]/batch_size) + 1, epochs=epochs)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        train(model, X,  batch_size, epoch, optimizer, scheduler)\n",
    "    emb = model.topics.get_topics().cpu().detach().numpy()\n",
    "    topics =  [[str(ind) for ind in np.argsort(emb[i])[::-1][:25] ] for i in range(numb_embeddings)]\n",
    "    data_batch = torch.from_numpy(X.toarray()).float()\n",
    "    model.cpu()\n",
    "    h = model.hidden(data_batch)\n",
    "    h = model.drop(h)\n",
    "    mu, log_sigma = model.normal(h)\n",
    "    z = model.h_to_z(mu)\n",
    "    result += evaluate(topics, X, z, labels)\n",
    "    pdf += [result]\n",
    "    pd.DataFrame(pdf).to_csv('gsm_result.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "03b81f29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.1]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "58ebc006",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[852, 114, 444, 222, 13, 10, 45, 3, 3, 1, 5, 6, 1, 1, 1, 1, 1]\n",
      "[922, 9, 165, 247, 39, 40, 25, 6, 3, 2, 8, 4, 3, 1, 2, 5, 3, 1, 4, 1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.09142523612437653,\n",
       " 0.05306401815449709,\n",
       " 0.07906186989281545,\n",
       " 0.04809175504402425,\n",
       " -2.1699192849931492,\n",
       " 0.08258238579931092,\n",
       " 0.08258238579931093,\n",
       " 0.08258238579931093,\n",
       " 0.08258238579931093,\n",
       " 0.08258238579931093,\n",
       " 0.08258238579931093,\n",
       " 0.08258238579931093,\n",
       " 0.08258238579931093,\n",
       " 0.08258238579931093,\n",
       " 0.08258238579931093,\n",
       " 0.08258238579931093,\n",
       " 0.08258238579931093,\n",
       " 0.08258238579931093,\n",
       " 0.08258238579931093,\n",
       " 0.08258238579931093,\n",
       " 0.08258238579931095,\n",
       " 0.08258238579931095,\n",
       " 0.08258238579931095,\n",
       " 0.08258238579931095,\n",
       " 0.08258238579931095,\n",
       " 0.536016927230133,\n",
       " 0.536016927230133,\n",
       " 0.536016927230133,\n",
       " 0.536016927230133,\n",
       " 0.536016927230133,\n",
       " 0.536016927230133,\n",
       " 0.536016927230133,\n",
       " 0.536016927230133,\n",
       " 0.536016927230133,\n",
       " 0.536016927230133,\n",
       " 0.536016927230133,\n",
       " 0.536016927230133,\n",
       " 0.5360169272301331,\n",
       " 0.5360169272301331,\n",
       " 0.5360169272301331,\n",
       " 0.5360169272301331,\n",
       " 0.5360169272301331,\n",
       " 0.5360169272301331,\n",
       " 0.5360169272301331,\n",
       " 0.5360169272301332]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e6ddf97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8847a362",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/ipykernel/__main__.py:16: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[893, 837, 845, 582, 289, 821, 371, 712, 719, 1, 15]\n",
      "[800, 156, 702, 711, 153, 408, 176, 245, 811, 429, 611, 598, 161, 89, 132, 125, 180, 144, 206, 87]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.24,\n",
       " 0.24,\n",
       " 0.52,\n",
       " 0.52,\n",
       " 0.52,\n",
       " 0.56,\n",
       " 0.6,\n",
       " 0.76,\n",
       " 0.92,\n",
       " 1.0,\n",
       " 0.3228801867770349,\n",
       " 0.41982885388588964,\n",
       " 0.367398917542184,\n",
       " 0.418928198549303,\n",
       " -2.5155681338841136,\n",
       " -0.004246315719902591,\n",
       " 0.009250011116884164,\n",
       " 0.015947860063648848,\n",
       " 0.016623999768910807,\n",
       " 0.024740270344067478,\n",
       " 0.031372713131173256,\n",
       " 0.03817326942023648,\n",
       " 0.16384449351879934,\n",
       " 0.19023430200125338,\n",
       " 0.23307599784639488,\n",
       " 0.3544211477680313,\n",
       " 0.4221171970530066,\n",
       " 0.42948688114679656,\n",
       " 0.43567113607794133,\n",
       " 0.49566456333515096,\n",
       " 0.5224178117319039,\n",
       " 0.576256403596454,\n",
       " 0.6970673372046872,\n",
       " 0.7332098326412175,\n",
       " 0.7452441090914286]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(topics, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "289d56b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.588"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(result[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c4922fc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0719016601491466"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " np.mean([-0.004246315719902591,\n",
    " 0.016623999768910807,\n",
    " 0.015947860063648848,\n",
    " 0.03817326942023648,\n",
    " 0.031372713131173256,\n",
    " 0.23307599784639488,\n",
    " 0.024740270344067478,\n",
    " 0.009250011116884164,\n",
    " 0.19023430200125338,\n",
    " 0.16384449351879934])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9280c44d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_latest_p36",
   "language": "python",
   "name": "conda_pytorch_latest_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
