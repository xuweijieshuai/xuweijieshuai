{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d64476e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from gensim.models import Word2Vec\n",
    "import sys\n",
    "#change to any directory you have to store the repo\n",
    "sys.path.insert(1, '/home/ec2-user/SageMaker/github/aspect_topic_modeling')\n",
    "\n",
    "from src.features.metric import diversity, get_topic_coherence\n",
    "from models.atten_model import MODEL_ATT_COMP\n",
    "import swifter\n",
    "from src.models.utils import get_wordnet_pos, remove_stopWords, get_emb, generate_emb, train, get_common_words, generate_bow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b4e975c",
   "metadata": {},
   "outputs": [],
   "source": [
    "D = pd.read_csv(\"/home/ec2-user/SageMaker/github/aspect_topic_modeling/src/data/train.txt\",header = None)\n",
    "D.iloc[:,0] = D.iloc[:,0].astype(str)\n",
    "sentences = [item.split() for item in D.iloc[:,0]]\n",
    "#generate word 2 vec models\n",
    "w2vmodel = Word2Vec(sentences,vector_size=200, window=10, negative = 5)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "25cdc0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate input\n",
    "vocab = list(set([j for i in D.values for j in i[0].split(' ') if j in w2vmodel.wv]))\n",
    "vocab = [''] + vocab\n",
    "word_track = {i: ind for ind, i in enumerate(vocab)}\n",
    "index_track = {ind: i for ind, i in enumerate(vocab)}\n",
    "D['index_num'] = D.swifter.apply(\n",
    "            lambda x: [word_track[i] for i in x[0].split() if i in word_track], axis=1)\n",
    "# X, indices = generate_bow(df = D, common_words = vocab)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "db3ebb61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(279885, 13590)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "74a0ca19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "mlb = MultiLabelBinarizer()\n",
    "XX = mlb.fit_transform([[word_track[it] for it in i if it in word_track] + [0]  for i in sentences])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e094c00f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pad the input\n",
    "\n",
    "vocab_tensor = torch.Tensor([[0] * 200]  + [w2vmodel.wv[i] for i in vocab[1:]])\n",
    "vocab_ind = [torch.LongTensor([word_track[it] for it in i if it in word_track][:16]) for i in sentences]\n",
    "input = torch.nn.utils.rnn.pad_sequence(vocab_ind, batch_first=True, padding_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e1a238",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.functional import normalize\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "class MODEL_ATT_COMP(nn.Module):\n",
    "    def __init__(self, d_word, d_key, d_value,n_topic, embeddings):\n",
    "        super(MODEL_ATT_COMP, self).__init__()\n",
    "        self.embeddings = nn.Embedding(len(embeddings), 200)\n",
    "        self.embeddings.weight = torch.nn.Parameter(embeddings)\n",
    "        self.embeddings.weight.requires_grad = False\n",
    "        self.K = nn.Linear(d_word,d_key)\n",
    "        self.Q = nn.Linear(d_word,d_key)\n",
    "        self.V = nn.Linear(d_word,d_value)\n",
    "        self.V2T = nn.Linear(d_value,n_topic)\n",
    "        self.soft1 = nn.Softmax(dim = 2)\n",
    "        self.T2V = nn.Linear(n_topic,d_value)\n",
    "        self.V2W = nn.Linear(d_value,d_word)\n",
    "        self.sqrtdk = torch.tensor([d_key**0.5]).to(device)\n",
    "    \n",
    "    def loss_max_margin_neg_sample(self, x):\n",
    "        word_repre_x = normalize(self.word_repre, dim = 2) #batch n dvalue\n",
    "        value_recon_x = normalize(self.value_recon, dim = 2) #batch n dvalue\n",
    "        sim_matrix = torch.matmul(word_repre_x, value_recon_x.transpose(2,1)) #batch n n\n",
    "        sim_x = torch.diagonal(sim_matrix, 0, 1, 2) #batch n \n",
    "        ns = torch.randperm(sim_x.shape[1]) # n \n",
    "        loss =  1 - sim_x + torch.diagonal(sim_matrix[:, ns], 0, 1, 2)\n",
    "        loss = loss.mean(1)  #batch \n",
    "        return loss\n",
    "\n",
    "    def loss_word_prediction_no_self(self, x):\n",
    "        word_recon_no_self_normalized = normalize(self.word_recon_no_self, dim = 2) #batch n d_word\n",
    "        x_normalized = normalize(x, dim = 2).transpose(2,1) #batch d_word n \n",
    "        sim_matrix = torch.matmul(word_recon_no_self_normalized, x_normalized) #batch n n\n",
    "        return 1 - torch.diagonal(sim_matrix, 0, 1, 2).mean(1) #batch \n",
    "\n",
    "    def reconstruction_loss(self):\n",
    "        distribution = self.topic_weight\n",
    "        return - torch.log(distribution) * distribution\n",
    "    \n",
    "    def similarity_loss(self):\n",
    "        d1, d2, d3 = self.att_weight.shape\n",
    "        normal_weights = self.att_weight.reshape(-1, d3) # batch * n n\n",
    "        samples = torch.multinomial(normal_weights, 1).reshape(-1) #batch * n\n",
    "        normalize_weights = normalize(self.topic_weight, dim = 2)\n",
    "        topic_similarity = torch.matmul(normalize_weights, normalize_weights.transpose(1,2)).reshape(d1*d2, -1) #batch n n\n",
    "        #print(topic_similarity.shape, samples.shape)\n",
    "        return 1 - topic_similarity[torch.arange(topic_similarity.shape[0]), samples].reshape(d1, d2).mean(1) #batch n\n",
    "         \n",
    "    def word_topics(self):\n",
    "        x = self.embeddings.weight\n",
    "        self.soft2 = nn.Softmax(dim = 1)\n",
    "        self.k = self.K(x).transpose(0,1) #d_key n \n",
    "        self.q = self.Q(x) #n d_key\n",
    "        self.att_score = torch.matmul(self.q, self.k) #n n\n",
    "        self.att_weight = self.soft2(self.att_score/self.sqrtdk) #n n, row sum = 1\n",
    "        self.v = self.V(x) #n d_key\n",
    "        self.word_repre = torch.matmul(self.att_weight, self.v) #batch n d_value\n",
    "        self.topic_score = self.V2T(self.word_repre) #n n_topic\n",
    "        self.word2topic = self.soft2(self.topic_score) #n n_topic, row sum = 1       \n",
    "        return self.word2topic\n",
    "    \n",
    "    def forward(self,x):\n",
    "        '''\n",
    "        x: tensor, n by d_word\n",
    "        '''\n",
    "        x = self.embeddings(x) #batch n d_word\n",
    "        self.k = self.K(x).transpose(2,1) #batch d_key n \n",
    "        self.q = self.Q(x) #batch n d_key\n",
    "        self.att_score = torch.matmul(self.q, self.k) #batch n n\n",
    "        self.att_weight = self.soft1(self.att_score/self.sqrtdk) #batch n n, row sum = 1\n",
    "        self.v = self.V(x) #batch n d_key\n",
    "        self.word_repre = torch.matmul(self.att_weight, self.v) #batch n d_value\n",
    "        self.topic_score = self.V2T(self.word_repre) #batch n n_topic\n",
    "        self.topic_weight = self.soft1(self.topic_score) #batch n n_topic, row sum = 1\n",
    "        self.value_recon = self.T2V(self.topic_weight) #batch n d_value\n",
    "        self.word_recon = self.V2W(self.word_repre)#batch n d_word\n",
    "        #no self computation, effectively masked\n",
    "        #print(self.k.shape, self.att_score.shape, self.att_weight.shape, self.word_repre.shape, self.topic_weight.shape)\n",
    "        self.att_score_no_self = self.att_score -  torch.diag(torch.zeros(self.att_score.shape[1])+torch.tensor(float('inf'))).to(device)#batch n n\n",
    "        self.att_weight_no_self = self.soft1(self.att_score_no_self/self.sqrtdk) #batch n n \n",
    "        self.word_repre_no_self = torch.matmul(self.att_weight_no_self, self.v)#batch n d_key\n",
    "        self.word_recon_no_self = self.V2W(self.word_repre_no_self) #batch n d_word\n",
    "        word_pred_loss = self.loss_word_prediction_no_self(x).sum()\n",
    "        margin_loss = self.loss_max_margin_neg_sample(x).sum()\n",
    "        recon_loss = self.reconstruction_loss().mean(1).sum()\n",
    "        sim_loss = self.similarity_loss().sum()\n",
    "        return {\n",
    "            'loss' : word_pred_loss + margin_loss,\n",
    "            'margin_loss': margin_loss,\n",
    "            'word_loss': word_pred_loss,\n",
    "            'reconstruct_loss': recon_loss,\n",
    "            'similarity_loss': sim_loss\n",
    "            \n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "17eb9dd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(512.6777, device='cuda:0', grad_fn=<AddBackward0>) tensor(256.0007, device='cuda:0', grad_fn=<SumBackward0>) tensor(256.6771, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(502.6732, device='cuda:0', grad_fn=<AddBackward0>) tensor(255.9948, device='cuda:0', grad_fn=<SumBackward0>) tensor(246.6784, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(490.3693, device='cuda:0', grad_fn=<AddBackward0>) tensor(255.7669, device='cuda:0', grad_fn=<SumBackward0>) tensor(234.6024, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(477.7612, device='cuda:0', grad_fn=<AddBackward0>) tensor(254.5385, device='cuda:0', grad_fn=<SumBackward0>) tensor(223.2227, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(470.8660, device='cuda:0', grad_fn=<AddBackward0>) tensor(250.4775, device='cuda:0', grad_fn=<SumBackward0>) tensor(220.3885, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(454.6784, device='cuda:0', grad_fn=<AddBackward0>) tensor(239.2022, device='cuda:0', grad_fn=<SumBackward0>) tensor(215.4762, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(445.5643, device='cuda:0', grad_fn=<AddBackward0>) tensor(228.7259, device='cuda:0', grad_fn=<SumBackward0>) tensor(216.8385, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(418.0268, device='cuda:0', grad_fn=<AddBackward0>) tensor(201.8250, device='cuda:0', grad_fn=<SumBackward0>) tensor(216.2018, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(397.8860, device='cuda:0', grad_fn=<AddBackward0>) tensor(181.4576, device='cuda:0', grad_fn=<SumBackward0>) tensor(216.4283, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(392.3581, device='cuda:0', grad_fn=<AddBackward0>) tensor(176.5117, device='cuda:0', grad_fn=<SumBackward0>) tensor(215.8464, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(403.8392, device='cuda:0', grad_fn=<AddBackward0>) tensor(183.7589, device='cuda:0', grad_fn=<SumBackward0>) tensor(220.0802, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(381.9133, device='cuda:0', grad_fn=<AddBackward0>) tensor(165.6817, device='cuda:0', grad_fn=<SumBackward0>) tensor(216.2316, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(356.8377, device='cuda:0', grad_fn=<AddBackward0>) tensor(138.1589, device='cuda:0', grad_fn=<SumBackward0>) tensor(218.6788, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(328.9269, device='cuda:0', grad_fn=<AddBackward0>) tensor(112.4918, device='cuda:0', grad_fn=<SumBackward0>) tensor(216.4351, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(356.7681, device='cuda:0', grad_fn=<AddBackward0>) tensor(138.5899, device='cuda:0', grad_fn=<SumBackward0>) tensor(218.1782, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(332.4216, device='cuda:0', grad_fn=<AddBackward0>) tensor(115.0478, device='cuda:0', grad_fn=<SumBackward0>) tensor(217.3738, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(323.0179, device='cuda:0', grad_fn=<AddBackward0>) tensor(107.9361, device='cuda:0', grad_fn=<SumBackward0>) tensor(215.0818, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(350.0711, device='cuda:0', grad_fn=<AddBackward0>) tensor(134.9104, device='cuda:0', grad_fn=<SumBackward0>) tensor(215.1607, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(332.1317, device='cuda:0', grad_fn=<AddBackward0>) tensor(114.3958, device='cuda:0', grad_fn=<SumBackward0>) tensor(217.7359, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(355.6770, device='cuda:0', grad_fn=<AddBackward0>) tensor(141.7586, device='cuda:0', grad_fn=<SumBackward0>) tensor(213.9184, device='cuda:0', grad_fn=<SumBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#--------------------------------------------\n",
    "#model param\n",
    "#--------------------------------------------\n",
    "d_word = w2vmodel.vector_size\n",
    "n_topic = 14\n",
    "batch_size = 256\n",
    "d_key = 50\n",
    "d_value = 50\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "#---------------------------------------\n",
    "#train model\n",
    "#---------------------------------------\n",
    "np.random.seed(10)\n",
    "model = MODEL_ATT_COMP(d_key = d_key, d_word = d_word, n_topic = n_topic, d_value = d_value, embeddings = vocab_tensor)\n",
    "model.to(device)\n",
    "learning_rate = 5 * 1e-5\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "for i in range(2000):\n",
    "    idx_batch = np.random.choice(np.arange(D.shape[0]),batch_size, replace = False)\n",
    "    x = input[idx_batch].to(device)\n",
    "    d = model.forward(x)\n",
    "    loss = d['loss']\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if i % 100 == 0:\n",
    "        print(d['loss'], d['margin_loss'], d['word_loss'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "7ba41019",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6428571428571429, -0.2500997513313553)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#report results for coherence and diversity\n",
    "del emb\n",
    "gc.collect()\n",
    "emb = model.word_topics().cpu()\n",
    "topics = [[vocab[j] for j in i] for i in emb.argsort(0)[-10:, :].t().detach().cpu().numpy() ]\n",
    "coherences= get_topic_coherence(XX, topics, word_track)\n",
    "np.mean(diversity(topics)), coherences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "c4b28631",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(342.0538, device='cuda:0', grad_fn=<AddBackward0>) tensor(126.5413, device='cuda:0', grad_fn=<SumBackward0>) tensor(215.5125, device='cuda:0', grad_fn=<SumBackward0>) tensor(18.0474, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(314.5013, device='cuda:0', grad_fn=<AddBackward0>) tensor(94.5565, device='cuda:0', grad_fn=<SumBackward0>) tensor(219.9447, device='cuda:0', grad_fn=<SumBackward0>) tensor(16.4558, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(301.7924, device='cuda:0', grad_fn=<AddBackward0>) tensor(88.4152, device='cuda:0', grad_fn=<SumBackward0>) tensor(213.3773, device='cuda:0', grad_fn=<SumBackward0>) tensor(17.3890, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(325.7821, device='cuda:0', grad_fn=<AddBackward0>) tensor(108.7282, device='cuda:0', grad_fn=<SumBackward0>) tensor(217.0539, device='cuda:0', grad_fn=<SumBackward0>) tensor(18.8047, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(345.7769, device='cuda:0', grad_fn=<AddBackward0>) tensor(127.5820, device='cuda:0', grad_fn=<SumBackward0>) tensor(218.1949, device='cuda:0', grad_fn=<SumBackward0>) tensor(15.4181, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(307.3797, device='cuda:0', grad_fn=<AddBackward0>) tensor(92.9135, device='cuda:0', grad_fn=<SumBackward0>) tensor(214.4662, device='cuda:0', grad_fn=<SumBackward0>) tensor(13.8113, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(349.2390, device='cuda:0', grad_fn=<AddBackward0>) tensor(135.5362, device='cuda:0', grad_fn=<SumBackward0>) tensor(213.7028, device='cuda:0', grad_fn=<SumBackward0>) tensor(13.1462, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(323.0131, device='cuda:0', grad_fn=<AddBackward0>) tensor(107.2925, device='cuda:0', grad_fn=<SumBackward0>) tensor(215.7206, device='cuda:0', grad_fn=<SumBackward0>) tensor(10.1927, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(348.7870, device='cuda:0', grad_fn=<AddBackward0>) tensor(135.6439, device='cuda:0', grad_fn=<SumBackward0>) tensor(213.1431, device='cuda:0', grad_fn=<SumBackward0>) tensor(10.2062, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(319.3984, device='cuda:0', grad_fn=<AddBackward0>) tensor(106.8323, device='cuda:0', grad_fn=<SumBackward0>) tensor(212.5662, device='cuda:0', grad_fn=<SumBackward0>) tensor(6.3889, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(329.5659, device='cuda:0', grad_fn=<AddBackward0>) tensor(118.0366, device='cuda:0', grad_fn=<SumBackward0>) tensor(211.5294, device='cuda:0', grad_fn=<SumBackward0>) tensor(1.7316, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(317.0698, device='cuda:0', grad_fn=<AddBackward0>) tensor(101.8242, device='cuda:0', grad_fn=<SumBackward0>) tensor(215.2457, device='cuda:0', grad_fn=<SumBackward0>) tensor(1.3583, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(297.7009, device='cuda:0', grad_fn=<AddBackward0>) tensor(81.3149, device='cuda:0', grad_fn=<SumBackward0>) tensor(216.3860, device='cuda:0', grad_fn=<SumBackward0>) tensor(1.0659, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(347.8618, device='cuda:0', grad_fn=<AddBackward0>) tensor(133.5884, device='cuda:0', grad_fn=<SumBackward0>) tensor(214.2734, device='cuda:0', grad_fn=<SumBackward0>) tensor(0.8296, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(295.0250, device='cuda:0', grad_fn=<AddBackward0>) tensor(81.0430, device='cuda:0', grad_fn=<SumBackward0>) tensor(213.9820, device='cuda:0', grad_fn=<SumBackward0>) tensor(0.8920, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(309.1972, device='cuda:0', grad_fn=<AddBackward0>) tensor(97.0732, device='cuda:0', grad_fn=<SumBackward0>) tensor(212.1240, device='cuda:0', grad_fn=<SumBackward0>) tensor(0.8733, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(314.9410, device='cuda:0', grad_fn=<AddBackward0>) tensor(99.7892, device='cuda:0', grad_fn=<SumBackward0>) tensor(215.1518, device='cuda:0', grad_fn=<SumBackward0>) tensor(0.7750, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(265.3592, device='cuda:0', grad_fn=<AddBackward0>) tensor(51.5748, device='cuda:0', grad_fn=<SumBackward0>) tensor(213.7844, device='cuda:0', grad_fn=<SumBackward0>) tensor(0.8790, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(286.1098, device='cuda:0', grad_fn=<AddBackward0>) tensor(74.4181, device='cuda:0', grad_fn=<SumBackward0>) tensor(211.6917, device='cuda:0', grad_fn=<SumBackward0>) tensor(0.7696, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(292.6746, device='cuda:0', grad_fn=<AddBackward0>) tensor(80.6033, device='cuda:0', grad_fn=<SumBackward0>) tensor(212.0713, device='cuda:0', grad_fn=<SumBackward0>) tensor(0.9018, device='cuda:0', grad_fn=<SumBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for i in range(2000):\n",
    "    idx_batch = np.random.choice(np.arange(D.shape[0]),batch_size, replace = False)\n",
    "    x = input[idx_batch].to(device)\n",
    "    d = model.forward(x)\n",
    "    loss = d['loss'] + d['similarity_loss']\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if i % 100 == 0:\n",
    "        print(d['loss'], d['margin_loss'], d['word_loss'], d['similarity_loss'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "ec7c7c6a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "dimension mismatch",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-103-c8b41968bae4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0memb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_topics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtopics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0memb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mcoherences\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mget_topic_coherence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword_track\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdiversity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtopics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoherences\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/SageMaker/github/aspect_topic_modeling/src/features/metric.py\u001b[0m in \u001b[0;36mget_topic_coherence\u001b[0;34m(data, topics, w2ind)\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mj\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtop_words\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mj\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m                 \u001b[0;31m# get D(w_j) and D(w_i, w_j)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m                 \u001b[0mD_wj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mD_wi_wj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_document_frequency\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw2ind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop_words\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m                 \u001b[0;31m# get f(w_i, w_j)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mD_wi_wj\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/SageMaker/github/aspect_topic_modeling/src/features/metric.py\u001b[0m in \u001b[0;36mget_document_frequency\u001b[0;34m(data, wi, w2ind, wj)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mindex2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mw2ind\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mwj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex2\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;34m>=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/scipy/sparse/base.py\u001b[0m in \u001b[0;36m__mul__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    477\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0missparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    478\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 479\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'dimension mismatch'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    480\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mul_sparse_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: dimension mismatch"
     ]
    }
   ],
   "source": [
    "del emb\n",
    "gc.collect()\n",
    "emb = model.word_topics().cpu()\n",
    "topics = [[vocab[j] for j in i] for i in emb.argsort(0)[-10:, :].t().detach().cpu().numpy() ]\n",
    "coherences= get_topic_coherence(XX, topics, word_track)\n",
    "np.mean(diversity(topics)), coherences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "bf5ea8db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.31428571428571433, 0.10776733456458878)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb6fa63d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_latest_p36",
   "language": "python",
   "name": "conda_pytorch_latest_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
